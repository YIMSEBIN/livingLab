{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Known issue with torch==2.4.0 on Windows with CPU, recommend upgrading to torch>=2.4.1 to resolve https://github.com/ultralytics/ultralytics/issues/15049\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79 images with 'rf' in the name.\n",
      "Processing: test\\images\\-7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\-7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg: 640x640 1 PP bag, 38.1ms\n",
      "Speed: 2.0ms preprocess, 38.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg: 640x640 1 General Waste, 2 CleanNets, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg: 640x640 3 General Wastes, 2 CleanNets, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg: 640x640 2 General Wastes, 2 CleanNets, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg: 640x640 1 Large Waste Items, 3 General Wastes, 1 CleanNet, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg: 640x640 1 Large Waste Items, 2 General Wastes, 1 CleanNet, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg: 640x640 3 General Wastes, 2 CleanNets, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg: 640x640 2 Large Waste Itemss, 3 General Wastes, 1 CleanNet, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg: 640x640 2 General Wastes, 2 CleanNets, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg: 640x640 4 General Wastes, 2 CleanNets, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg: 640x640 2 General Wastes, 2 CleanNets, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg: 640x640 1 General Waste, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg: 640x640 1 Large Waste Items, 4 General Wastes, 2 CleanNets, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg: 640x640 2 General Wastes, 2 CleanNets, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg: 640x640 4 General Wastes, 2 CleanNets, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg: 640x640 3 General Wastes, 2 CleanNets, 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg: 640x640 4 General Wastes, 1 CleanNet, 26.5ms\n",
      "Speed: 1.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg: 640x640 1 General Waste, 2 CleanNets, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg: 640x640 4 General Wastes, 2 CleanNets, 30.5ms\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg: 640x640 3 General Wastes, 3 CleanNets, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg: 640x640 3 Large Waste Itemss, 1 General Waste, 1 CleanNet, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg: 640x640 3 General Wastes, 2 CleanNets, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg: 640x640 2 Large Waste Itemss, 2 General Wastes, 2 CleanNets, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg: 640x640 2 General Wastes, 2 CleanNets, 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg: 640x640 3 General Wastes, 2 CleanNets, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg: 640x640 4 General Wastes, 3 CleanNets, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg: 640x640 1 Large Waste Items, 1 PP bag, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg: 640x640 1 Large Waste Items, 5 PP bags, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg: 640x640 4 General Wastes, 2 CleanNets, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg: 640x640 3 General Wastes, 2 CleanNets, 25.3ms\n",
      "Speed: 1.0ms preprocess, 25.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg: 640x640 3 Large Waste Itemss, 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg: 640x640 5 Large Waste Itemss, 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg: 640x640 4 Large Waste Itemss, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg: 640x640 2 Large Waste Itemss, 5 General Wastes, 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg: 640x640 4 Large Waste Itemss, 4 PP bags, 1 General Waste, 33.4ms\n",
      "Speed: 2.0ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg: 640x640 2 Large Waste Itemss, 40.8ms\n",
      "Speed: 1.6ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg: 640x640 6 Large Waste Itemss, 25.6ms\n",
      "Speed: 1.0ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg: 640x640 2 Large Waste Itemss, 2 General Wastes, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg: 640x640 9 Large Waste Itemss, 1 General Waste, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg: 640x640 2 General Wastes, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg: 640x640 1 Large Waste Items, 1 CleanNet, 27.0ms\n",
      "Speed: 2.5ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg: 640x640 3 Large Waste Itemss, 2 CleanNets, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg: 640x640 22 PP bags, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg: 640x640 1 PP bag, 2 General Wastes, 1 CleanNet, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg: 640x640 1 PP bag, 1 CleanNet, 43.1ms\n",
      "Speed: 1.6ms preprocess, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg: 640x640 2 Large Waste Itemss, 2 General Wastes, 2 CleanNets, 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg: 640x640 3 CleanNets, 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg: 640x640 2 Large Waste Itemss, 3 General Wastes, 3 CleanNets, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg: 640x640 3 Large Waste Itemss, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg: 640x640 2 CleanNets, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg: 640x640 6 General Wastes, 2 CleanNets, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg: 640x640 1 General Waste, 2 CleanNets, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg: 640x640 3 General Wastes, 2 CleanNets, 24.5ms\n",
      "Speed: 1.0ms preprocess, 24.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg: 640x640 3 General Wastes, 2 CleanNets, 34.0ms\n",
      "Speed: 1.0ms preprocess, 34.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg: 640x640 7 General Wastes, 2 CleanNets, 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg: 640x640 2 CleanNets, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg: 640x640 1 General Waste, 4 CleanNets, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg: 640x640 2 General Wastes, 3 CleanNets, 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg: 640x640 4 General Wastes, 2 CleanNets, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg: 640x640 2 General Wastes, 2 CleanNets, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg: 640x640 (no detections), 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg: 640x640 2 CleanNets, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg: 640x640 8 General Wastes, 3 CleanNets, 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg: 640x640 4 General Wastes, 2 CleanNets, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg: 640x640 1 CleanNet, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg: 640x640 1 Large Waste Items, 2 General Wastes, 2 CleanNets, 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg: 640x640 2 CleanNets, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg: 640x640 2 Large Waste Itemss, 1 PP bag, 1 General Waste, 2 CleanNets, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg: 640x640 8 General Wastes, 2 CleanNets, 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg: 640x640 4 General Wastes, 2 CleanNets, 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg: 640x640 4 General Wastes, 2 CleanNets, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg: 640x640 1 General Waste, 5 CleanNets, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg: 640x640 1 General Waste, 2 CleanNets, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg: 640x640 1 Large Waste Items, 5 General Wastes, 2 CleanNets, 25.0ms\n",
      "Speed: 1.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg: 640x640 4 General Wastes, 2 CleanNets, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg: 640x640 1 General Waste, 1 CleanNet, 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg: 640x640 2 PP bags, 2 General Wastes, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg: 640x640 3 PP bags, 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processing: test\\images\\40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC \\ \\\\YOLOv8 \\test\\images\\40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg: 640x640 3 PP bags, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "Processed 79 images. Results saved to ./runs/detect/predict/\n",
      "Image 1: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\-7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg\n",
      "Detected Classes: ['PP bag']\n",
      "Image 2: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Image 3: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 4: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 5: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'General Waste', 'Large Waste Items', 'General Waste']\n",
      "Image 6: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg\n",
      "Detected Classes: ['Large Waste Items', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 7: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 8: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'General Waste', 'Large Waste Items', 'Large Waste Items', 'General Waste']\n",
      "Image 9: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 10: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 11: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 12: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg\n",
      "Detected Classes: ['General Waste']\n",
      "Image 13: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'Large Waste Items', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 14: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 15: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 16: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 17: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 18: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Image 19: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 20: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 21: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg\n",
      "Detected Classes: ['Large Waste Items', 'CleanNet', 'General Waste', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 22: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 23: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'Large Waste Items', 'General Waste', 'Large Waste Items']\n",
      "Image 24: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 25: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 26: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 27: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg\n",
      "Detected Classes: ['Large Waste Items', 'PP bag']\n",
      "Image 28: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg\n",
      "Detected Classes: ['PP bag', 'PP bag', 'Large Waste Items', 'PP bag', 'PP bag', 'PP bag']\n",
      "Image 29: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 30: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 31: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 32: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 33: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 34: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg\n",
      "Detected Classes: ['General Waste', 'Large Waste Items', 'General Waste', 'General Waste', 'Large Waste Items', 'General Waste', 'General Waste']\n",
      "Image 35: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg\n",
      "Detected Classes: ['PP bag', 'Large Waste Items', 'PP bag', 'Large Waste Items', 'General Waste', 'Large Waste Items', 'PP bag', 'PP bag', 'Large Waste Items']\n",
      "Image 36: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items']\n",
      "Image 37: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 38: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg\n",
      "Detected Classes: ['General Waste', 'General Waste', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 39: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'General Waste', 'Large Waste Items']\n",
      "Image 40: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg\n",
      "Detected Classes: ['General Waste', 'General Waste']\n",
      "Image 41: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg\n",
      "Detected Classes: ['CleanNet', 'Large Waste Items']\n",
      "Image 42: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items', 'CleanNet', 'CleanNet', 'Large Waste Items']\n",
      "Image 43: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg\n",
      "Detected Classes: ['PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag']\n",
      "Image 44: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'General Waste', 'PP bag']\n",
      "Image 45: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg\n",
      "Detected Classes: ['CleanNet', 'PP bag']\n",
      "Image 46: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg\n",
      "Detected Classes: ['CleanNet', 'Large Waste Items', 'Large Waste Items', 'General Waste', 'CleanNet', 'General Waste']\n",
      "Image 47: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'CleanNet']\n",
      "Image 48: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 49: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg\n",
      "Detected Classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Image 50: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet']\n",
      "Image 51: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'General Waste', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 52: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Image 53: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 54: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 55: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 56: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet']\n",
      "Image 57: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'CleanNet', 'CleanNet']\n",
      "Image 58: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'CleanNet', 'General Waste']\n",
      "Image 59: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 60: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Image 61: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg\n",
      "Detected Classes: []\n",
      "Image 62: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet']\n",
      "Image 63: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 64: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 65: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg\n",
      "Detected Classes: ['CleanNet']\n",
      "Image 66: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'Large Waste Items']\n",
      "Image 67: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet']\n",
      "Image 68: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg\n",
      "Detected Classes: ['CleanNet', 'Large Waste Items', 'General Waste', 'CleanNet', 'PP bag', 'Large Waste Items']\n",
      "Image 69: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 70: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 71: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 72: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'CleanNet', 'CleanNet', 'CleanNet']\n",
      "Image 73: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Image 74: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'CleanNet', 'Large Waste Items', 'General Waste']\n",
      "Image 75: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg\n",
      "Detected Classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Image 76: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg\n",
      "Detected Classes: ['CleanNet', 'General Waste']\n",
      "Image 77: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg\n",
      "Detected Classes: ['PP bag', 'PP bag', 'General Waste', 'General Waste']\n",
      "Image 78: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg\n",
      "Detected Classes: ['PP bag', 'PP bag', 'PP bag']\n",
      "Image 79: c:\\Users\\JeongYeonju\\Desktop\\yeonjuLab\\Project\\DSC 지역리빙랩\\프로젝트 활동\\코드\\YOLOv8기반 객체인식\\test\\images\\40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg\n",
      "Detected Classes: ['PP bag', 'PP bag', 'PP bag']\n"
     ]
    }
   ],
   "source": [
    "# 1. 모델 로드\n",
    "model = YOLO('./results_20241124_155336/waste_detection_model/weights/best.pt')  # 학습한 모델 경로 지정\n",
    "\n",
    "# 2. 이미지 디렉토리 설정\n",
    "image_dir = './test/images/'  # 이미지 디렉토리\n",
    "output_dir = './runs/detect/predict/'  # 결과 저장 디렉토리\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 3. \"rf\"가 포함된 파일만 필터링\n",
    "image_paths = [path for path in Path(image_dir).glob(\"*.jpg\") if \"rf\" in path.stem]  # 파일 이름 조건 추가\n",
    "print(f\"Found {len(image_paths)} images with 'rf' in the name.\")\n",
    "\n",
    "# 4. 탐지 수행\n",
    "results = []  # 전체 결과 저장 리스트\n",
    "for image_path in image_paths:\n",
    "    print(f\"Processing: {image_path}\")\n",
    "    result = model.predict(source=str(image_path), save=True, device='cpu')  # 예측 수행\n",
    "    results.append(result[0])  # 단일 이미지 결과 저장\n",
    "\n",
    "print(f\"Processed {len(results)} images. Results saved to {output_dir}\")\n",
    "\n",
    "# 5. 결과 확인\n",
    "for idx, result in enumerate(results):\n",
    "    print(f\"Image {idx + 1}: {result.path}\")\n",
    "    print(f\"Detected Classes: {[result.names[int(cls_id)] for cls_id in result.boxes.cls]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    # 대형폐기물 (Large Waste Items)\n",
    "    'arcade machine': 'Large Waste Items', 'Audio': 'Large Waste Items', 'Computer': 'Large Waste Items',\n",
    "    'fax machine': 'Large Waste Items', 'Main unit': 'Large Waste Items', 'Monitor': 'Large Waste Items',\n",
    "    'Printer': 'Large Waste Items', 'sewing machine': 'Large Waste Items', 'Speaker': 'Large Waste Items',\n",
    "    'typewriter': 'Large Waste Items', 'Vacuum cleaner': 'Large Waste Items', 'Video player': 'Large Waste Items',\n",
    "    'Bathtub': 'Large Waste Items', 'Sink': 'Large Waste Items', 'Kitchen sink': 'Large Waste Items',\n",
    "    'Toilet bowl': 'Large Waste Items', 'Bed': 'Large Waste Items', 'Bookcase': 'Large Waste Items',\n",
    "    'Bookstand': 'Large Waste Items', 'Cabinet': 'Large Waste Items', 'chair': 'Large Waste Items',\n",
    "    'Cupboard': 'Large Waste Items', 'Desk': 'Large Waste Items', 'Dining table': 'Large Waste Items',\n",
    "    'Display cabinet': 'Large Waste Items', 'Display stand': 'Large Waste Items', 'Drawer unit': 'Large Waste Items',\n",
    "    'Shoe rack': 'Large Waste Items', 'Small cabinet': 'Large Waste Items', 'Sofa': 'Large Waste Items',\n",
    "    'Table': 'Large Waste Items', 'TV stand': 'Large Waste Items', 'Vanity table': 'Large Waste Items',\n",
    "    'Wardrobe': 'Large Waste Items', 'Air conditioner': 'Large Waste Items', 'Air purifier': 'Large Waste Items',\n",
    "    'dish dryer': 'Large Waste Items', 'Electric rice cooker': 'Large Waste Items', 'Fan': 'Large Waste Items',\n",
    "    'Gas oven range': 'Large Waste Items', 'Heater': 'Large Waste Items', 'Humidifier': 'Large Waste Items',\n",
    "    'Microwave': 'Large Waste Items', 'refrigerator': 'Large Waste Items', 'Spin dryer': 'Large Waste Items',\n",
    "    'TV': 'Large Waste Items', 'Washing machine': 'Large Waste Items', 'Aquarium': 'Large Waste Items',\n",
    "    'Bamboo mat': 'Large Waste Items', 'Bedding items': 'Large Waste Items', 'bicycle': 'Large Waste Items',\n",
    "    'Carpet': 'Large Waste Items', 'Clothes drying rack': 'Large Waste Items', 'Coat rack': 'Large Waste Items',\n",
    "    'Door panel': 'Large Waste Items', 'Earthenware jar': 'Large Waste Items', 'Floor covering': 'Large Waste Items',\n",
    "    'Frame': 'Large Waste Items', 'lumber': 'Large Waste Items', 'Mannequin': 'Large Waste Items',\n",
    "    'Mat': 'Large Waste Items', 'Piano': 'Large Waste Items', 'Rice storage container': 'Large Waste Items',\n",
    "    'Signboard': 'Large Waste Items', 'Stroller': 'Large Waste Items', 'Wall clock': 'Large Waste Items',\n",
    "    'Water tank': 'Large Waste Items', 'audio cabinet': 'Large Waste Items', 'suitcase': 'Large Waste Items',\n",
    "    \n",
    "    'PP bag': 'PP bag',\n",
    "    'General waste bag': 'General Waste',\n",
    "    'waste pile': 'General Waste',\n",
    "    'CleanNet': 'CleanNet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_labels_to_major_category(json_path, category_mapping):\n",
    "    \"\"\"소분류를 대분류로 변환.\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    converted_data = {}\n",
    "    for image_name, annotations in data.items():\n",
    "        converted_annotations = []\n",
    "        for ann in annotations:\n",
    "            class_name = ann[\"class_name\"]\n",
    "            if class_name in category_mapping:\n",
    "                major_category = category_mapping[class_name]\n",
    "                converted_annotations.append({\n",
    "                    \"class_name\": major_category,\n",
    "                    \"bbox\": ann[\"bbox\"]\n",
    "                })\n",
    "        converted_data[image_name] = converted_annotations\n",
    "\n",
    "    return converted_data\n",
    "\n",
    "# 라벨링 데이터 변환 실행\n",
    "json_path = './test/test_annotations_yolo.json'  # 라벨링 JSON 경로\n",
    "converted_labels = convert_labels_to_major_category(json_path, category_mapping)\n",
    "\n",
    "# 변환된 데이터 저장 (선택)\n",
    "with open('./test/converted_annotations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(converted_labels, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 'Large Waste Items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg, Classification: Negative\n",
      "Image: 202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg, Classification: Negative\n",
      "Image: 202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg, Classification: Positive\n",
      "Image: 202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg, Classification: Positive\n",
      "Image: 202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg, Classification: Negative\n",
      "Image: 202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg, Classification: Positive\n",
      "Image: 202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg, Classification: Negative\n",
      "Image: 202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg, Classification: Negative\n",
      "Image: 202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg, Classification: Negative\n",
      "Image: 202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg, Classification: Positive\n",
      "Image: 202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg, Classification: Negative\n",
      "Image: 202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg, Classification: Positive\n",
      "Image: -7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg, Classification: Negative\n",
      "Image: 202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg, Classification: Negative\n",
      "Image: 202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg, Classification: Positive\n",
      "Image: 202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg, Classification: Negative\n",
      "Image: 202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg, Classification: Negative\n",
      "Image: 202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg, Classification: Positive\n",
      "Image: 202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg, Classification: Negative\n",
      "Image: 202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg, Classification: Positive\n",
      "Image: 202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg, Classification: Negative\n",
      "Image: 202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg, Classification: Negative\n",
      "Image: 202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg, Classification: Negative\n",
      "Image: 202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg, Classification: Negative\n",
      "Image: 202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg, Classification: Positive\n",
      "Image: 202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg, Classification: Negative\n",
      "Image: 202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg, Classification: Positive\n",
      "Image: 202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg, Classification: Positive\n",
      "Image: 202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg, Classification: Negative\n",
      "Image: 202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg, Classification: Negative\n",
      "Image: 202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg, Classification: Positive\n",
      "Image: 202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg, Classification: Negative\n",
      "Image: 202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg, Classification: Negative\n",
      "Image: 202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg, Classification: Positive\n",
      "Image: 202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg, Classification: Negative\n",
      "Image: 202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg, Classification: Positive\n",
      "Image: 202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg, Classification: Positive\n",
      "Image: 23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg, Classification: Negative\n",
      "Image: 202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg, Classification: Positive\n",
      "Image: 202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg, Classification: Negative\n",
      "Image: 202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg, Classification: Negative\n",
      "Image: 202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg, Classification: Positive\n",
      "Image: 202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg, Classification: Negative\n",
      "Image: 202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg, Classification: Negative\n",
      "Image: 202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg, Classification: Negative\n",
      "Image: 202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg, Classification: Negative\n",
      "Image: 202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg, Classification: Negative\n",
      "Image: 202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg, Classification: Negative\n",
      "Image: 202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg, Classification: Negative\n",
      "Image: 202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg, Classification: Negative\n",
      "Image: 202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg, Classification: Positive\n",
      "Image: 202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg, Classification: Negative\n",
      "Image: 202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg, Classification: Negative\n",
      "Image: 202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg, Classification: Positive\n",
      "Image: 202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg, Classification: Negative\n",
      "Image: 202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg, Classification: Negative\n",
      "Image: 202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg, Classification: Negative\n",
      "Image: 202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg, Classification: Negative\n",
      "Image: 280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg, Classification: Negative\n",
      "Image: 202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg, Classification: Negative\n",
      "Image: 202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg, Classification: Positive\n",
      "Image: 202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg, Classification: Positive\n",
      "Image: 202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg, Classification: Positive\n",
      "Image: 202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg, Classification: Negative\n",
      "Image: 40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg, Classification: Negative\n",
      "Image: 202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg, Classification: Negative\n",
      "Image: 202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg, Classification: Positive\n",
      "Image: 202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg, Classification: Negative\n",
      "Image: 202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg, Classification: Positive\n",
      "Image: 202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg, Classification: Negative\n",
      "Image: 202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg, Classification: Negative\n",
      "Image: 202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg, Classification: Positive\n",
      "Image: 202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg, Classification: Negative\n",
      "Image: 202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg, Classification: Negative\n",
      "Image: 202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg, Classification: Negative\n",
      "Image: 202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg, Classification: Negative\n",
      "Image: 202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg, Classification: Negative\n",
      "Image: 202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg, Classification: Negative\n",
      "Image: 202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg, Classification: Negative\n"
     ]
    }
   ],
   "source": [
    "def classify_images_by_major_category(converted_labels, target_class):\n",
    "    \"\"\"대분류 기준으로 이미지를 이진 분류.\"\"\"\n",
    "    binary_classification = {}\n",
    "\n",
    "    for image_name, annotations in converted_labels.items():\n",
    "        # 이미지의 모든 객체가 target_class인지 확인\n",
    "        if any(ann[\"class_name\"] == target_class for ann in annotations):\n",
    "            binary_classification[image_name] = \"Positive\"\n",
    "        else:\n",
    "            binary_classification[image_name] = \"Negative\"\n",
    "    \n",
    "    return binary_classification\n",
    "\n",
    "# 이진 분류 실행\n",
    "binary_classification = classify_images_by_major_category(converted_labels, target_class)\n",
    "\n",
    "# 결과 출력\n",
    "for image_name, classification in binary_classification.items():\n",
    "    print(f\"Image: {image_name}, Classification: {classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_results(results, target_class):\n",
    "    \"\"\"객체 탐지 결과를 이진 분류로 변환.\"\"\"\n",
    "    binary_classification = {}\n",
    "\n",
    "    for result in results:\n",
    "        image_path = result.path  # 이미지 경로\n",
    "        image_name = image_path.split('\\\\')[-1]  # 이미지 이름만 추출\n",
    "        detected_classes = [result.names[int(cls_id)] for cls_id in result.boxes.cls]\n",
    "\n",
    "        # 이진 분류 조건: target_class 존재 여부\n",
    "        if target_class in detected_classes:\n",
    "            binary_classification[image_name] = \"Positive\"\n",
    "        else:\n",
    "            binary_classification[image_name] = \"Negative\"\n",
    "    \n",
    "    return binary_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "classify_results() missing 1 required positional argument: 'target_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m comparison\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 탐지 결과와 라벨링 데이터 비교\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m binary_results \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 탐지 결과 이진 분류\u001b[39;00m\n\u001b[0;32m     16\u001b[0m comparison \u001b[38;5;241m=\u001b[39m compare_results_and_labels(binary_results, binary_classification, target_class)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatching Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomparison[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: classify_results() missing 1 required positional argument: 'target_class'"
     ]
    }
   ],
   "source": [
    "def compare_results_and_labels(binary_results, binary_labels):\n",
    "    \"\"\"탐지 결과와 라벨링 데이터의 이진 분류 결과 비교.\"\"\"\n",
    "    comparison = {\"match\": 0, \"mismatch\": 0}\n",
    "\n",
    "    for image_name, label in binary_labels.items():\n",
    "        prediction = binary_results.get(image_name, \"Negative\")  # 탐지 결과 없으면 Negative로 기본 설정\n",
    "        if prediction == label:\n",
    "            comparison[\"match\"] += 1\n",
    "        else:\n",
    "            comparison[\"mismatch\"] += 1\n",
    "\n",
    "    return comparison\n",
    "\n",
    "# 탐지 결과와 라벨링 데이터 비교\n",
    "binary_results = classify_results(results)  # 탐지 결과 이진 분류\n",
    "comparison = compare_results_and_labels(binary_results, binary_classification, target_class)\n",
    "\n",
    "print(f\"Matching Results: {comparison['match']}\")\n",
    "print(f\"Mismatched Results: {comparison['mismatch']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_classification(predicted, ground_truth):\n",
    "    \"\"\"\n",
    "    이진 분류 결과 평가.\n",
    "    Args:\n",
    "        predicted: 탐지 결과의 이진 분류 (딕셔너리, {image_name: \"Positive\"/\"Negative\"}).\n",
    "        ground_truth: 라벨링 데이터의 이진 분류 (딕셔너리, {image_name: \"Positive\"/\"Negative\"}).\n",
    "    Returns:\n",
    "        성능 지표 딕셔너리 (정확도, 정밀도, 재현율, F1-Score).\n",
    "    \"\"\"\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    true_negative = 0\n",
    "\n",
    "    for image_name, gt_label in ground_truth.items():\n",
    "        pred_label = predicted.get(image_name, \"Negative\")  # 탐지 결과 없으면 Negative로 처리\n",
    "\n",
    "        if pred_label == \"Positive\" and gt_label == \"Positive\":\n",
    "            true_positive += 1\n",
    "        elif pred_label == \"Positive\" and gt_label == \"Negative\":\n",
    "            false_positive += 1\n",
    "        elif pred_label == \"Negative\" and gt_label == \"Positive\":\n",
    "            false_negative += 1\n",
    "        elif pred_label == \"Negative\" and gt_label == \"Negative\":\n",
    "            true_negative += 1\n",
    "\n",
    "    # 정확도 (Accuracy)\n",
    "    print(true_positive, false_positive, false_negative, true_negative)\n",
    "    total = true_positive + false_positive + false_negative + true_negative\n",
    "    accuracy = (true_positive + true_negative) / total if total > 0 else 0\n",
    "\n",
    "    # 정밀도 (Precision)\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "\n",
    "    # 재현율 (Recall)\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "\n",
    "    # F1-Score\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_performance_metrics(target_class):\n",
    "    binary_results = classify_results(results, target_class=target_class)  # 탐지 결과를 이진 분류\n",
    "    binary_labels = classify_images_by_major_category(converted_labels, target_class=target_class)  # 라벨링 데이터 이진 분류\n",
    "    performance_metrics = evaluate_binary_classification(binary_results, binary_labels)\n",
    "\n",
    "    print(\"Performance Metrics:\")\n",
    "    for metric, value in performance_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 5 5 49\n",
      "Performance Metrics:\n",
      "Accuracy: 0.8734\n",
      "Precision: 0.8000\n",
      "Recall: 0.8000\n",
      "F1-Score: 0.8000\n"
     ]
    }
   ],
   "source": [
    "final_performance_metrics('Large Waste Items') # 대형폐기물 존재 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 1 67\n",
      "Performance Metrics:\n",
      "Accuracy: 0.9747\n",
      "Precision: 0.9091\n",
      "Recall: 0.9091\n",
      "F1-Score: 0.9091\n"
     ]
    }
   ],
   "source": [
    "final_performance_metrics('PP bag') # PP마대 존재 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo+cleanNet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
