{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 필요한 라이브러리 임포트\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: 카테고리 매핑 정의\n",
    "category_mapping = {\n",
    "    # 대형폐기물 (Large Waste Items)\n",
    "    'arcade machine': 'Large Waste Items',\n",
    "    'Audio': 'Large Waste Items',\n",
    "    'Computer': 'Large Waste Items',\n",
    "    'fax machine': 'Large Waste Items',\n",
    "    'Main unit': 'Large Waste Items',\n",
    "    'Monitor': 'Large Waste Items',\n",
    "    'Printer': 'Large Waste Items',\n",
    "    'sewing machine': 'Large Waste Items',\n",
    "    'Speaker': 'Large Waste Items',\n",
    "    'typewriter': 'Large Waste Items',\n",
    "    'Vacuum cleaner': 'Large Waste Items',\n",
    "    'Video player': 'Large Waste Items',\n",
    "    'Bathtub': 'Large Waste Items',\n",
    "    'Sink': 'Large Waste Items',\n",
    "    'Kitchen sink': 'Large Waste Items',\n",
    "    'Toilet bowl': 'Large Waste Items',\n",
    "    'Bed': 'Large Waste Items',\n",
    "    'Bookcase': 'Large Waste Items',\n",
    "    'Bookstand': 'Large Waste Items',\n",
    "    'Cabinet': 'Large Waste Items',\n",
    "    'chair': 'Large Waste Items',\n",
    "    'Cupboard': 'Large Waste Items',\n",
    "    'Desk': 'Large Waste Items',\n",
    "    'Dining table': 'Large Waste Items',\n",
    "    'Display cabinet': 'Large Waste Items',\n",
    "    'Display stand': 'Large Waste Items',\n",
    "    'Drawer unit': 'Large Waste Items',\n",
    "    'Shoe rack': 'Large Waste Items',\n",
    "    'Small cabinet': 'Large Waste Items',\n",
    "    'Sofa': 'Large Waste Items',\n",
    "    'Table': 'Large Waste Items',\n",
    "    'TV stand': 'Large Waste Items',\n",
    "    'Vanity table': 'Large Waste Items',\n",
    "    'Wardrobe': 'Large Waste Items',\n",
    "    'Air conditioner': 'Large Waste Items',\n",
    "    'Air purifier': 'Large Waste Items',\n",
    "    'dish dryer': 'Large Waste Items',\n",
    "    'Electric rice cooker': 'Large Waste Items',\n",
    "    'Fan': 'Large Waste Items',\n",
    "    'Gas oven range': 'Large Waste Items',\n",
    "    'Heater': 'Large Waste Items',\n",
    "    'Humidifier': 'Large Waste Items',\n",
    "    'Microwave': 'Large Waste Items',\n",
    "    'refrigerator': 'Large Waste Items',\n",
    "    'Spin dryer': 'Large Waste Items',\n",
    "    'TV': 'Large Waste Items',\n",
    "    'Washing machine': 'Large Waste Items',\n",
    "    'Aquarium': 'Large Waste Items',\n",
    "    'Bamboo mat': 'Large Waste Items',\n",
    "    'Bedding items': 'Large Waste Items',\n",
    "    'bicycle': 'Large Waste Items',\n",
    "    'Carpet': 'Large Waste Items',\n",
    "    'Clothes drying rack': 'Large Waste Items',\n",
    "    'Coat rack': 'Large Waste Items',\n",
    "    'Door panel': 'Large Waste Items',\n",
    "    'Earthenware jar': 'Large Waste Items',\n",
    "    'Floor covering': 'Large Waste Items',\n",
    "    'Frame': 'Large Waste Items',\n",
    "    'lumber': 'Large Waste Items',\n",
    "    'Mannequin': 'Large Waste Items',\n",
    "    'Mat': 'Large Waste Items',\n",
    "    'Piano': 'Large Waste Items',\n",
    "    'Rice storage container': 'Large Waste Items',\n",
    "    'Signboard': 'Large Waste Items',\n",
    "    'Stroller': 'Large Waste Items',\n",
    "    'Wall clock': 'Large Waste Items',\n",
    "    'Water tank': 'Large Waste Items',\n",
    "    'audio cabinet': 'Large Waste Items',\n",
    "    'suitcase': 'Large Waste Items',\n",
    "    \n",
    "    # 기타 카테고리\n",
    "    'PP bag': 'PP bag',\n",
    "    'General waste bag': 'General Waste',\n",
    "    'waste pile': 'General Waste',\n",
    "    'CleanNet': 'CleanNet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 폴더 내 모든 이미지 객체 감지용 함수\n",
    "def detect_objects(model_path, image_dir):\n",
    "    # 모델 로드\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # 출력 디렉토리 생성\n",
    "    output_dir = './runs/detect/predict/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 모든 이미지 파일 가져오기 (jpg, jpeg, png)\n",
    "    image_paths = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "        image_paths.extend(list(Path(image_dir).glob(ext)))\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images in the directory.\")\n",
    "    \n",
    "    results = []\n",
    "    for idx, image_path in enumerate(image_paths, 1):\n",
    "        print(f\"\\nProcessing image {idx}/{len(image_paths)}: {image_path.name}\")\n",
    "        result = model.predict(source=str(image_path), save=True, device='cpu')\n",
    "        results.append(result[0])\n",
    "        \n",
    "        # 각 이미지의 감지 결과 출력\n",
    "        detected_classes = [result[0].names[int(cls_id)] for cls_id in result[0].boxes.cls]\n",
    "        print(f\"Detected Classes in {image_path.name}:\")\n",
    "        for cls in detected_classes:\n",
    "            print(f\"- {cls}\")\n",
    "        \n",
    "        # 처리 속도 정보 출력\n",
    "        preprocess_time = result[0].speed['preprocess']\n",
    "        inference_time = result[0].speed['inference']\n",
    "        postprocess_time = result[0].speed['postprocess']\n",
    "        print(f\"Processing times:\")\n",
    "        print(f\"- Preprocess: {preprocess_time}ms\")\n",
    "        print(f\"- Inference: {inference_time}ms\")\n",
    "        print(f\"- Postprocess: {postprocess_time}ms\")\n",
    "        \n",
    "    print(f\"\\nAll results saved to {output_dir}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: JSON 라벨 변환 함수\n",
    "def convert_labels_to_major_category(json_path, category_mapping):\n",
    "    # JSON 파일 로드\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    converted_data = {}\n",
    "    for image_name, annotations in data.items():\n",
    "        converted_annotations = []\n",
    "        for ann in annotations:\n",
    "            class_name = ann[\"class_name\"]\n",
    "            if class_name in category_mapping:\n",
    "                major_category = category_mapping[class_name]\n",
    "                converted_annotations.append({\n",
    "                    \"class_name\": major_category,\n",
    "                    \"bbox\": ann[\"bbox\"]\n",
    "                })\n",
    "        converted_data[image_name] = converted_annotations\n",
    "    \n",
    "    return converted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 이진 분류 함수\n",
    "def classify_images_by_major_category(converted_labels, target_class):\n",
    "    binary_classification = {}\n",
    "    \n",
    "    for image_name, annotations in converted_labels.items():\n",
    "        if any(ann[\"class_name\"] == target_class for ann in annotations):\n",
    "            binary_classification[image_name] = \"Positive\"\n",
    "        else:\n",
    "            binary_classification[image_name] = \"Negative\"\n",
    "            \n",
    "        # 상세 정보 출력\n",
    "        detected_classes = [ann[\"class_name\"] for ann in annotations]\n",
    "        print(f\"\\nImage: {image_name}\")\n",
    "        print(f\"Detected classes: {detected_classes}\")\n",
    "        print(f\"Classification: {binary_classification[image_name]}\")\n",
    "    \n",
    "    return binary_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: 결과 저장 함수\n",
    "def save_results(binary_classification, output_path):\n",
    "    results_summary = {\n",
    "        \"total_images\": len(binary_classification),\n",
    "        \"positive_count\": sum(1 for v in binary_classification.values() if v == \"Positive\"),\n",
    "        \"negative_count\": sum(1 for v in binary_classification.values() if v == \"Negative\"),\n",
    "        \"classifications\": binary_classification\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results_summary, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    return results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: 메인 실행 코드\n",
    "def main():\n",
    "    # 경로 설정\n",
    "    model_path = r'E:\\livingLab\\YOLOv8기반 객체인식\\results_20241124_155336\\waste_detection_model\\weights\\best.pt'\n",
    "    image_dir = r'E:\\livingLab\\YOLOv8기반 객체인식\\test\\images'\n",
    "    json_path = r'E:\\livingLab\\YOLOv8기반 객체인식\\test\\test_annotations_yolo.json'\n",
    "    target_class = 'Large Waste Items'\n",
    "    \n",
    "    # 1. 객체 감지 실행\n",
    "    print(\"Starting object detection...\")\n",
    "    results = detect_objects(model_path, image_dir)\n",
    "    \n",
    "    # 2. 라벨 변환\n",
    "    print(\"\\nConverting labels to major categories...\")\n",
    "    converted_labels = convert_labels_to_major_category(json_path, category_mapping)\n",
    "    \n",
    "    # 3. 이진 분류 실행\n",
    "    print(\"\\nPerforming binary classification...\")\n",
    "    binary_classification = classify_images_by_major_category(converted_labels, target_class)\n",
    "    \n",
    "    # 4. 결과 저장\n",
    "    output_path = './test/classification_results.json'\n",
    "    results_summary = save_results(binary_classification, output_path)\n",
    "    \n",
    "    # 5. 최종 결과 출력\n",
    "    print(\"\\nClassification Summary:\")\n",
    "    print(f\"Total images processed: {results_summary['total_images']}\")\n",
    "    print(f\"Positive classifications: {results_summary['positive_count']}\")\n",
    "    print(f\"Negative classifications: {results_summary['negative_count']}\")\n",
    "    print(f\"\\nDetailed results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting object detection...\n",
      "Found 79 images in the directory.\n",
      "\n",
      "Processing image 1/79: -7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\-7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg: 640x640 1 PP bag, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in -7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg:\n",
      "- PP bag\n",
      "Processing times:\n",
      "- Preprocess: 1.992940902709961ms\n",
      "- Inference: 44.67272758483887ms\n",
      "- Postprocess: 0.9961128234863281ms\n",
      "\n",
      "Processing image 2/79: 202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg: 640x640 1 General Waste, 2 CleanNets, 39.2ms\n",
      "Speed: 2.0ms preprocess, 39.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 2.003192901611328ms\n",
      "- Inference: 39.16192054748535ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 3/79: 202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg: 640x640 3 General Wastes, 2 CleanNets, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 37.9948616027832ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 4/79: 202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg: 640x640 2 General Wastes, 2 CleanNets, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9936561584472656ms\n",
      "- Inference: 36.96393966674805ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 5/79: 202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg: 640x640 1 Large Waste Items, 4 General Wastes, 1 CleanNet, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9936561584472656ms\n",
      "- Inference: 37.0173454284668ms\n",
      "- Postprocess: 0.9970664978027344ms\n",
      "\n",
      "Processing image 6/79: 202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg: 640x640 1 Large Waste Items, 1 General Waste, 1 CleanNet, 37.6ms\n",
      "Speed: 1.0ms preprocess, 37.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg:\n",
      "- Large Waste Items\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 37.64963150024414ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 7/79: 202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg: 640x640 3 General Wastes, 2 CleanNets, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9931793212890625ms\n",
      "- Inference: 36.94725036621094ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 8/79: 202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg: 640x640 2 Large Waste Itemss, 2 General Wastes, 1 CleanNet, 37.6ms\n",
      "Speed: 2.0ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 1.9931793212890625ms\n",
      "- Inference: 37.57214546203613ms\n",
      "- Postprocess: 0.9970664978027344ms\n",
      "\n",
      "Processing image 9/79: 202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg: 640x640 2 General Wastes, 2 CleanNets, 35.9ms\n",
      "Speed: 2.0ms preprocess, 35.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.993417739868164ms\n",
      "- Inference: 35.88056564331055ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 10/79: 202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg: 640x640 4 General Wastes, 2 CleanNets, 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9963512420654297ms\n",
      "- Inference: 38.038015365600586ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 11/79: 202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg: 640x640 2 General Wastes, 2 CleanNets, 38.4ms\n",
      "Speed: 2.0ms preprocess, 38.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9931793212890625ms\n",
      "- Inference: 38.38515281677246ms\n",
      "- Postprocess: 0.9968280792236328ms\n",
      "\n",
      "Processing image 12/79: 202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg: 640x640 1 General Waste, 31.6ms\n",
      "Speed: 1.0ms preprocess, 31.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg:\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9963512420654297ms\n",
      "- Inference: 31.551837921142578ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 13/79: 202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg: 640x640 1 Large Waste Items, 4 General Wastes, 2 CleanNets, 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 2.0036697387695312ms\n",
      "- Inference: 37.06860542297363ms\n",
      "- Postprocess: 1.0085105895996094ms\n",
      "\n",
      "Processing image 14/79: 202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg: 640x640 2 General Wastes, 2 CleanNets, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 37.531137466430664ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 15/79: 202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg: 640x640 3 General Wastes, 2 CleanNets, 52.4ms\n",
      "Speed: 1.0ms preprocess, 52.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 52.364349365234375ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 16/79: 202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg: 640x640 3 General Wastes, 2 CleanNets, 33.1ms\n",
      "Speed: 1.2ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.2402534484863281ms\n",
      "- Inference: 33.05363655090332ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 17/79: 202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg: 640x640 4 General Wastes, 1 CleanNet, 31.2ms\n",
      "Speed: 1.0ms preprocess, 31.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 31.218767166137695ms\n",
      "- Postprocess: 1.0111331939697266ms\n",
      "\n",
      "Processing image 18/79: 202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg: 640x640 1 General Waste, 2 CleanNets, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.992940902709961ms\n",
      "- Inference: 30.568838119506836ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 19/79: 202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg: 640x640 4 General Wastes, 2 CleanNets, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.001119613647461ms\n",
      "- Inference: 30.97367286682129ms\n",
      "- Postprocess: 0.9975433349609375ms\n",
      "\n",
      "Processing image 20/79: 202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg: 640x640 3 General Wastes, 3 CleanNets, 32.6ms\n",
      "Speed: 1.0ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 32.56869316101074ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 21/79: 202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg: 640x640 3 Large Waste Itemss, 1 General Waste, 1 CleanNet, 30.2ms\n",
      "Speed: 1.0ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg:\n",
      "- Large Waste Items\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 30.23242950439453ms\n",
      "- Postprocess: 0.9958744049072266ms\n",
      "\n",
      "Processing image 22/79: 202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg: 640x640 3 General Wastes, 2 CleanNets, 31.2ms\n",
      "Speed: 1.0ms preprocess, 31.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 31.186342239379883ms\n",
      "- Postprocess: 0.9973049163818359ms\n",
      "\n",
      "Processing image 23/79: 202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg: 640x640 2 Large Waste Itemss, 2 General Wastes, 2 CleanNets, 32.1ms\n",
      "Speed: 1.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9963512420654297ms\n",
      "- Inference: 32.1354866027832ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 24/79: 202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg: 640x640 2 General Wastes, 2 CleanNets, 31.1ms\n",
      "Speed: 1.0ms preprocess, 31.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 31.108617782592773ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 25/79: 202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg: 640x640 3 General Wastes, 2 CleanNets, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 30.124425888061523ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 26/79: 202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg: 640x640 4 General Wastes, 3 CleanNets, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 31.048297882080078ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 27/79: 202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg: 640x640 1 Large Waste Items, 1 PP bag, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg:\n",
      "- Large Waste Items\n",
      "- PP bag\n",
      "Processing times:\n",
      "- Preprocess: 1.9943714141845703ms\n",
      "- Inference: 37.0182991027832ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 28/79: 202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg: 640x640 1 Large Waste Items, 5 PP bags, 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg:\n",
      "- PP bag\n",
      "- PP bag\n",
      "- Large Waste Items\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "Processing times:\n",
      "- Preprocess: 1.992940902709961ms\n",
      "- Inference: 37.08052635192871ms\n",
      "- Postprocess: 0.9968280792236328ms\n",
      "\n",
      "Processing image 29/79: 202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg: 640x640 4 General Wastes, 2 CleanNets, 37.1ms\n",
      "Speed: 1.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9961128234863281ms\n",
      "- Inference: 37.137508392333984ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 30/79: 202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg: 640x640 3 General Wastes, 2 CleanNets, 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9941329956054688ms\n",
      "- Inference: 37.10627555847168ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 31/79: 202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg: 640x640 3 Large Waste Itemss, 37.1ms\n",
      "Speed: 1.1ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 1.1386871337890625ms\n",
      "- Inference: 37.097930908203125ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 32/79: 202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg: 640x640 5 Large Waste Itemss, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 1.046895980834961ms\n",
      "- Inference: 39.175987243652344ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 33/79: 202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg: 640x640 4 Large Waste Itemss, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9973049163818359ms\n",
      "- Inference: 39.10231590270996ms\n",
      "- Postprocess: 0.9968280792236328ms\n",
      "\n",
      "Processing image 34/79: 202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg: 640x640 2 Large Waste Itemss, 5 General Wastes, 30.2ms\n",
      "Speed: 1.0ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg:\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 30.218839645385742ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 35/79: 202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg: 640x640 4 Large Waste Itemss, 4 PP bags, 1 General Waste, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg:\n",
      "- PP bag\n",
      "- Large Waste Items\n",
      "- PP bag\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- PP bag\n",
      "- PP bag\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9963512420654297ms\n",
      "- Inference: 29.134273529052734ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 36/79: 202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg: 640x640 2 Large Waste Itemss, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 37.46342658996582ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 37/79: 202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg: 640x640 6 Large Waste Itemss, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9973049163818359ms\n",
      "- Inference: 37.68205642700195ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 38/79: 202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg: 640x640 2 Large Waste Itemss, 2 General Wastes, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg:\n",
      "- General Waste\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9963512420654297ms\n",
      "- Inference: 36.24534606933594ms\n",
      "- Postprocess: 0.9961128234863281ms\n",
      "\n",
      "Processing image 39/79: 202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg: 640x640 10 Large Waste Itemss, 1 General Waste, 38.1ms\n",
      "Speed: 1.0ms preprocess, 38.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 1.0085105895996094ms\n",
      "- Inference: 38.14291954040527ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 40/79: 202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg: 640x640 2 General Wastes, 33.5ms\n",
      "Speed: 1.0ms preprocess, 33.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg:\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 33.45012664794922ms\n",
      "- Postprocess: 0.9970664978027344ms\n",
      "\n",
      "Processing image 41/79: 202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg: 640x640 1 Large Waste Items, 1 CleanNet, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg:\n",
      "- CleanNet\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 1.0480880737304688ms\n",
      "- Inference: 29.001712799072266ms\n",
      "- Postprocess: 0.9970664978027344ms\n",
      "\n",
      "Processing image 42/79: 202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg: 640x640 3 Large Waste Itemss, 2 CleanNets, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 32.155513763427734ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 43/79: 202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg: 640x640 22 PP bags, 38.6ms\n",
      "Speed: 2.0ms preprocess, 38.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg:\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "Processing times:\n",
      "- Preprocess: 1.9938945770263672ms\n",
      "- Inference: 38.5890007019043ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 44/79: 202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg: 640x640 1 PP bag, 2 General Wastes, 1 CleanNet, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- PP bag\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 38.87152671813965ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 45/79: 202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg: 640x640 1 PP bag, 1 CleanNet, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg:\n",
      "- CleanNet\n",
      "- PP bag\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 39.94321823120117ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 46/79: 202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg: 640x640 2 Large Waste Itemss, 2 General Wastes, 2 CleanNets, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg:\n",
      "- CleanNet\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.993417739868164ms\n",
      "- Inference: 37.95313835144043ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 47/79: 202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg: 640x640 3 CleanNets, 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "Processing times:\n",
      "- Preprocess: 1.9938945770263672ms\n",
      "- Inference: 37.079811096191406ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 48/79: 202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg: 640x640 2 Large Waste Itemss, 3 General Wastes, 3 CleanNets, 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 1.9931793212890625ms\n",
      "- Inference: 37.053585052490234ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 49/79: 202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg: 640x640 3 Large Waste Itemss, 36.2ms\n",
      "Speed: 2.0ms preprocess, 36.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg:\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 1.9931793212890625ms\n",
      "- Inference: 36.23700141906738ms\n",
      "- Postprocess: 0.9958744049072266ms\n",
      "\n",
      "Processing image 50/79: 202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg: 640x640 2 CleanNets, 37.9ms\n",
      "Speed: 1.0ms preprocess, 37.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "Processing times:\n",
      "- Preprocess: 0.9973049163818359ms\n",
      "- Inference: 37.877559661865234ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 51/79: 202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg: 640x640 6 General Wastes, 2 CleanNets, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 38.202762603759766ms\n",
      "- Postprocess: 0.9968280792236328ms\n",
      "\n",
      "Processing image 52/79: 202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg: 640x640 1 General Waste, 2 CleanNets, 36.9ms\n",
      "Speed: 1.0ms preprocess, 36.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 36.895036697387695ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 53/79: 202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg: 640x640 3 General Wastes, 2 CleanNets, 38.3ms\n",
      "Speed: 2.0ms preprocess, 38.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9931793212890625ms\n",
      "- Inference: 38.28716278076172ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 54/79: 202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg: 640x640 2 General Wastes, 2 CleanNets, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9936561584472656ms\n",
      "- Inference: 30.408859252929688ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 55/79: 202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg: 640x640 7 General Wastes, 2 CleanNets, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.0058879852294922ms\n",
      "- Inference: 30.053377151489258ms\n",
      "- Postprocess: 0.9970664978027344ms\n",
      "\n",
      "Processing image 56/79: 202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg: 640x640 2 CleanNets, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "Processing times:\n",
      "- Preprocess: 0.9973049163818359ms\n",
      "- Inference: 29.079198837280273ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 57/79: 202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg: 640x640 1 General Waste, 4 CleanNets, 28.1ms\n",
      "Speed: 1.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "Processing times:\n",
      "- Preprocess: 0.9980201721191406ms\n",
      "- Inference: 28.122663497924805ms\n",
      "- Postprocess: 0.9968280792236328ms\n",
      "\n",
      "Processing image 58/79: 202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg: 640x640 2 General Wastes, 3 CleanNets, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.008749008178711ms\n",
      "- Inference: 36.956071853637695ms\n",
      "- Postprocess: 0.9968280792236328ms\n",
      "\n",
      "Processing image 59/79: 202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg: 640x640 4 General Wastes, 2 CleanNets, 34.3ms\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.5020370483398438ms\n",
      "- Inference: 34.26527976989746ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 60/79: 202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg: 640x640 2 General Wastes, 2 CleanNets, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.0094642639160156ms\n",
      "- Inference: 29.057025909423828ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 61/79: 202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg: 640x640 (no detections), 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg:\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 33.16760063171387ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 62/79: 202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg: 640x640 2 CleanNets, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "Processing times:\n",
      "- Preprocess: 1.0073184967041016ms\n",
      "- Inference: 30.139684677124023ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 63/79: 202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg: 640x640 8 General Wastes, 3 CleanNets, 31.5ms\n",
      "Speed: 1.0ms preprocess, 31.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 31.519412994384766ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 64/79: 202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg: 640x640 4 General Wastes, 2 CleanNets, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.993417739868164ms\n",
      "- Inference: 30.897140502929688ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 65/79: 202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg: 640x640 1 CleanNet, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg:\n",
      "- CleanNet\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 42.368173599243164ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 66/79: 202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg: 640x640 1 Large Waste Items, 2 General Wastes, 2 CleanNets, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9961128234863281ms\n",
      "- Inference: 30.031204223632812ms\n",
      "- Postprocess: 0.9977817535400391ms\n",
      "\n",
      "Processing image 67/79: 202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg: 640x640 1 General Waste, 2 CleanNets, 31.8ms\n",
      "Speed: 1.0ms preprocess, 31.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 31.751394271850586ms\n",
      "- Postprocess: 0.9970664978027344ms\n",
      "\n",
      "Processing image 68/79: 202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg: 640x640 2 Large Waste Itemss, 1 PP bag, 1 General Waste, 2 CleanNets, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg:\n",
      "- CleanNet\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- PP bag\n",
      "- Large Waste Items\n",
      "Processing times:\n",
      "- Preprocess: 0.9977817535400391ms\n",
      "- Inference: 29.079914093017578ms\n",
      "- Postprocess: 0.9965896606445312ms\n",
      "\n",
      "Processing image 69/79: 202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg: 640x640 8 General Wastes, 2 CleanNets, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 30.99536895751953ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 70/79: 202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg: 640x640 4 General Wastes, 2 CleanNets, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9989013671875ms\n",
      "- Inference: 30.97081184387207ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 71/79: 202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg: 640x640 4 General Wastes, 2 CleanNets, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9963512420654297ms\n",
      "- Inference: 29.97112274169922ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 72/79: 202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg: 640x640 1 General Waste, 5 CleanNets, 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "Processing times:\n",
      "- Preprocess: 1.992940902709961ms\n",
      "- Inference: 31.48937225341797ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 73/79: 202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg: 640x640 1 General Waste, 2 CleanNets, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9938945770263672ms\n",
      "- Inference: 30.89618682861328ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 74/79: 202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg: 640x640 1 Large Waste Items, 5 General Wastes, 2 CleanNets, 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- CleanNet\n",
      "- Large Waste Items\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.993417739868164ms\n",
      "- Inference: 29.311180114746094ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 75/79: 202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg: 640x640 4 General Wastes, 2 CleanNets, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg:\n",
      "- CleanNet\n",
      "- CleanNet\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9936561584472656ms\n",
      "- Inference: 29.995203018188477ms\n",
      "- Postprocess: 0.9968280792236328ms\n",
      "\n",
      "Processing image 76/79: 202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg: 640x640 1 General Waste, 1 CleanNet, 29.3ms\n",
      "Speed: 1.0ms preprocess, 29.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg:\n",
      "- CleanNet\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 0.9970664978027344ms\n",
      "- Inference: 29.265880584716797ms\n",
      "- Postprocess: 0.9963512420654297ms\n",
      "\n",
      "Processing image 77/79: 23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg: 640x640 2 PP bags, 2 General Wastes, 32.1ms\n",
      "Speed: 2.0ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg:\n",
      "- PP bag\n",
      "- PP bag\n",
      "- General Waste\n",
      "- General Waste\n",
      "Processing times:\n",
      "- Preprocess: 1.9936561584472656ms\n",
      "- Inference: 32.068490982055664ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 78/79: 280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg: 640x640 3 PP bags, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg:\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "Processing times:\n",
      "- Preprocess: 0.9968280792236328ms\n",
      "- Inference: 30.05814552307129ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "Processing image 79/79: 40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg\n",
      "\n",
      "image 1/1 E:\\livingLab\\YOLOv8 \\test\\images\\40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg: 640x640 3 PP bags, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict9\u001b[0m\n",
      "Detected Classes in 40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg:\n",
      "- PP bag\n",
      "- PP bag\n",
      "- PP bag\n",
      "Processing times:\n",
      "- Preprocess: 0.9965896606445312ms\n",
      "- Inference: 31.969547271728516ms\n",
      "- Postprocess: 0.0ms\n",
      "\n",
      "All results saved to ./runs/detect/predict/\n",
      "\n",
      "Converting labels to major categories...\n",
      "\n",
      "Performing binary classification...\n",
      "\n",
      "Image: 202411061348-36-313711-127-349988_jpg.rf.3581e8d79a3a050686554a20476cdb34.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061346-36-311745-127-353092_jpg.rf.3e408eccde358b63c05fd5a29f956aab.jpg\n",
      "Detected classes: ['General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111240-36-305737-127-350237_jpg.rf.07a211fd644530b35bcda797c76089f0.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111231-36-307637-127-351064_jpg.rf.089c4d450857dd4dca741be2cf4f1cbb.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061319-36-307974-127-355197_jpg.rf.40e66b47ea454f90ee055c740410cc1c.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061313-36-307488-127-352668_jpg.rf.2debbe814df92503a0079be859650cc0.jpg\n",
      "Detected classes: ['Large Waste Items', 'CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111223-36-307550-127-354681_jpg.rf.23480e44a8092c9c3311ca80c0ed1d96.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111216-36-309841-127-353640_jpg.rf.0cfe34d4e561604f27e4d6d51709d093.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111148-36-330942-127-338586_jpg.rf.09088434bf25f50d833296c7059228a4.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061431-36-309908-127-348185_jpg.rf.23fe7b1ddec31535d885e6cc9288d2da.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061348-36-310510-127-353380_jpg.rf.1b445c1bbde0cedac1df9b0f9c220dd4.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411081236-36-423913-127-407165-1_jpg.rf.0dfb1f31bd1bafebca3f8424e98cdc61.jpg\n",
      "Detected classes: ['General Waste', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: -7-_jpg.rf.3e4e45f01df8da1ac999a94efb60473e.jpg\n",
      "Detected classes: ['PP bag']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111237-36-306997-127-351164_jpg.rf.45266fd2de02a14c1c674892c8a0ae33.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061352-36-313215-127-351277-3_jpg.rf.46cfc13747bebd1a1755da3b8a3cd8dd.jpg\n",
      "Detected classes: ['General Waste', 'Large Waste Items', 'Large Waste Items', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111206-36-311745-127-353092_jpg.rf.175848f0b77ba404e4e6f11f44f8c590.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111221-36-307340-127-353540_jpg.rf.44607ac9cf9e836b2131ef722b16478e.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111150-36-331699-127-339169-2_jpg.rf.30de6ea0a36f7a5dff4c2d5633c75ff7.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061342-36-309176-127-351941_jpg.rf.05afb3c8e078242b96c4a730357296bb.jpg\n",
      "Detected classes: ['CleanNet', 'General Waste', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061423-36-313839-127-348579_jpg.rf.4c6e29fd453c998c1710c6dd014daacf.jpg\n",
      "Detected classes: ['General Waste', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'General Waste']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061337-36-309239-127-353916_jpg.rf.4c7a323affb98f997405ec20ca6d216e.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061330-36-318792-127-344275_jpg.rf.3f74fb24878d9a28014f79a8ad00e4c4.jpg\n",
      "Detected classes: ['General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111217-36-309239-127-353916_jpg.rf.45de2cd861119d382d4752616a1c7e31.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111150-36-331699-127-339169-1_jpg.rf.2dfbaba491bab23e08d12300bdec0a40.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061434-36-309502-127-348344_jpg.rf.18196b3699941fd051eb67f4246945bb.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'General Waste', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061349-36-313040-127-350293_jpg.rf.52fab8e4c82156dcff635e98319420f9.jpg\n",
      "Detected classes: ['General Waste', 'CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061323-36-319426-127-343581-2_jpg.rf.5c85eeb865231f3fb9ac4fd355319416.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061415-36-316636-127-347495_jpg.rf.79ef2fb18c5b765ead9711ec6516fcea.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111226-36-306967-127-355016-1_jpg.rf.7b71d120bd3741d88af836c1e341b460.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111210-36-310957-127-353130_jpg.rf.693876733d993c585b16039273a00299.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111238-36-306863-127-350438_jpg.rf.6129b71701b75171bd7c11bce00321de.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'Large Waste Items', 'Large Waste Items', 'General Waste', 'General Waste']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061339-36-310790-127-352166_jpg.rf.78fd2988c35f72ab7c8c932764bb04c6.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061342-36-315640-127-349174_jpg.rf.5444f5989d8b4ed01d08d05553d63571.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061322-36-320218-127-343319_jpg.rf.86814c1d60da676d5d9596a2a3da0efb.jpg\n",
      "Detected classes: ['CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061329-36-309133-127-353018_jpg.rf.66723f2b0a1f776c240789b2605d7c6e.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061423-36-314851-127-347123_jpg.rf.6b1796d5ce76d550ec8c684a8c23fafd.jpg\n",
      "Detected classes: ['General Waste', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'PP bag', 'Large Waste Items', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061431-36-311574-127-349342_jpg.rf.5182513e42f5000cf9af2f91816f2114.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'General Waste']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 23907_68481_2024_jpg.rf.b54912c39030808ac7c4302f5f2a9541.jpg\n",
      "Detected classes: ['PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061438-36-309254-127-350078_jpg.rf.63980ab462c1a491c72131a321aa9bc4.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061346-36-308081-127-353130_jpg.rf.83770fab01c2a2e62838a2a2729231a7.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061358-36-308465-127-354548_jpg.rf.965f2f2b47de25bdc9d795cb71576543.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061433-36-309089-127-349308_jpg.rf.680978375d34a5ce6bd988b65213fe68.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111207-36-310510-127-353380_jpg.rf.816d4f9ca63a539abb4e7bd0bfafc0e0.jpg\n",
      "Detected classes: ['General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061328-36-318467-127-342773_jpg.rf.8e7d885664cc4a093d1ef0afcc79b2e8.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111224-36-307974-127-355197_jpg.rf.8824813e9e1263d3c32b197514edcf0b.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061345-36-314850-127-350158_jpg.rf.a5c076f0199e673c36da4ac790ee940e.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061359-36-310957-127-353130_jpg.rf.906b474010a7ba8fcea77eeef01433cd.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061328-36-318047-127-344154_jpg.rf.7aefec6f116650e0e611553b9811a6d8.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111136-36-331616-127-335799_jpg.rf.896aa812873491b43e52dfbd3261d149.jpg\n",
      "Detected classes: ['PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111228-36-307488-127-352668_jpg.rf.c021bf13ef90ee8f5a21b75c386ba96e.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061423-36-315046-127-346080_jpg.rf.bdc3f041759c2e28c0f15e1397a3584d.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111137-36-331383-127-335375_jpg.rf.a50332a13cae1728d2c5dc6162c5b05d.jpg\n",
      "Detected classes: ['PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111246-36-324233-127-344985_jpg.rf.d4fac2031eba1010c932d2ba451f0b9e.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061346-36-314198-127-350451_jpg.rf.c77a12c283995fb4057bd0ca00b83161.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111234-36-306079-127-351546_jpg.rf.c9c863d9067d40dd0035692f3d78d305.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111220-36-308081-127-353130_jpg.rf.d482c4c6079ceee93fea151e3af3092a.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061322-36-307550-127-354681_jpg.rf.e09f59bc4cc8915a9da9c47c91f306f0.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'PP bag', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111251-36-322309-127-342752_jpg.rf.cee98eb6f397c8e712d2cc1e38b025ba.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 280-1-_jpg.rf.da456a3686d9264b2091920e32945993.jpg\n",
      "Detected classes: ['PP bag', 'PP bag']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061350-36-314129-127-351297_jpg.rf.7b7238965a8cae0683e4d2bac4f5a06a.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111139-36-331111-127-337848_jpg.rf.cbb982f1d1e160b11ae586add407ded9.jpg\n",
      "Detected classes: ['Large Waste Items', 'CleanNet']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061352-36-313215-127-351277-2_jpg.rf.f6aa801aed2a6e2e10462b781d4358bd.jpg\n",
      "Detected classes: ['PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411061418-36-315697-127-346125_jpg.rf.e9aab1e2970ae7ad8efb2ab0e3dd7b81.jpg\n",
      "Detected classes: ['General Waste', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111153-36-36-331686-127-340556_jpg.rf.f610735c1c46cf5328fb96c544f43dd2.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 40e6c194a7_jpg.rf.d53564843314e6adb88ef92998cdaf82.jpg\n",
      "Detected classes: ['PP bag']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061343-36-315732-127-349908_jpg.rf.f32a738af7e8cb0569568da90e660036.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'General Waste', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061420-36-315055-127-346190_jpg.rf.f735fd248bc6690f4c75068de0897d1f.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111212-36-310790-127-352166_jpg.rf.d4bb484b862d3105c60cdbe0712b5651.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'General Waste', 'CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111213-36-309176-127-351941_jpg.rf.ddc9885bd847ea5b84dc27ccf6fd9fd9.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'Large Waste Items']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111215-36-309133-127-353018_jpg.rf.d74fb20ba076ca562ab4b9922841c5e4.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111229-36-308507-127-351318_jpg.rf.d6a1f843c6a43aa44bb88941b03a0142.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061326-36-318897-127-343185_jpg.rf.d6707abf64c488ae79ddec26206a2f89.jpg\n",
      "Detected classes: ['Large Waste Items', 'Large Waste Items', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Classification: Positive\n",
      "\n",
      "Image: 202411111226-36-306652-127-353674_jpg.rf.bf1c0077ff4820a3e86121a92f4c3b79.jpg\n",
      "Detected classes: ['General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111241-36-305407-127-348838_jpg.rf.c9a72083f4584c5401821f536b962985.jpg\n",
      "Detected classes: ['General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411081236-36-423913-127-407165-2_jpg.rf.f6e2a098f84601afac7d2350a475d4cc.jpg\n",
      "Detected classes: ['PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag', 'PP bag']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061349-36-311745-127-353092_jpg.rf.fb5f4cbdb3036192e55d681050fe72da.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111252-36-321934-127-343575_jpg.rf.f74b0372f7638eef7e00d1d9f0c16f70.jpg\n",
      "Detected classes: ['General Waste', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411111156-36-331079-127-341792_jpg.rf.fe0c796d57c7083f244e29ed95c6585c.jpg\n",
      "Detected classes: ['General Waste', 'General Waste', 'General Waste', 'CleanNet', 'CleanNet']\n",
      "Classification: Negative\n",
      "\n",
      "Image: 202411061325-36-308399-127-354248_jpg.rf.fe8e74b6e0015e468fad270eb87ca499.jpg\n",
      "Detected classes: ['CleanNet', 'CleanNet', 'General Waste', 'General Waste']\n",
      "Classification: Negative\n",
      "\n",
      "Classification Summary:\n",
      "Total images processed: 79\n",
      "Positive classifications: 25\n",
      "Negative classifications: 54\n",
      "\n",
      "Detailed results saved to: ./test/classification_results.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: 스크립트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
