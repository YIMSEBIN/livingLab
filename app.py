##  ! í„°ë¯¸ë„ì— "streamlit run app.py" ë¼ê³  ì…ë ¥í•˜ë©´ ì‹¤í–‰ë¨ 

import glob
import time
import numpy as np
import streamlit as st
import os
import pandas as pd
from datetime import datetime
from streamlit import components
from ultralytics import YOLO
import cv2

from src.main import make_route
from src.visualize.visualize_nodes import visualize_nodemap
from src.visualize.visualize_routes import visualize_routemap

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ì˜
category_mapping = {
    # Large Waste Items
    'arcade machine': 'Large Waste Items',
    'Audio': 'Large Waste Items',
    'Computer': 'Large Waste Items',
    'fax machine': 'Large Waste Items',
    'Main unit': 'Large Waste Items',
    'Monitor': 'Large Waste Items',
    'Printer': 'Large Waste Items',
    'sewing machine': 'Large Waste Items',
    'Speaker': 'Large Waste Items',
    'typewriter': 'Large Waste Items',
    'Vacuum cleaner': 'Large Waste Items',
    'Video player': 'Large Waste Items',
    'Bathtub': 'Large Waste Items',
    'Sink': 'Large Waste Items',
    'Kitchen sink': 'Large Waste Items',
    'Toilet bowl': 'Large Waste Items',
    'Bed': 'Large Waste Items',
    'Bookcase': 'Large Waste Items',
    'Bookstand': 'Large Waste Items',
    'Cabinet': 'Large Waste Items',
    'chair': 'Large Waste Items',
    'Cupboard': 'Large Waste Items',
    'Desk': 'Large Waste Items',
    'Dining table': 'Large Waste Items',
    'Display cabinet': 'Large Waste Items',
    'Display stand': 'Large Waste Items',
    'Drawer unit': 'Large Waste Items',
    'Shoe rack': 'Large Waste Items',
    'Small cabinet': 'Large Waste Items',
    'Sofa': 'Large Waste Items',
    'Table': 'Large Waste Items',
    'TV stand': 'Large Waste Items',
    'Vanity table': 'Large Waste Items',
    'Wardrobe': 'Large Waste Items',
    'Air conditioner': 'Large Waste Items',
    'Air purifier': 'Large Waste Items',
    'dish dryer': 'Large Waste Items',
    'Electric rice cooker': 'Large Waste Items',
    'Fan': 'Large Waste Items',
    'Gas oven range': 'Large Waste Items',
    'Heater': 'Large Waste Items',
    'Humidifier': 'Large Waste Items',
    'Microwave': 'Large Waste Items',
    'refrigerator': 'Large Waste Items',
    'Spin dryer': 'Large Waste Items',
    'TV': 'Large Waste Items',
    'Washing machine': 'Large Waste Items',
    'Aquarium': 'Large Waste Items',
    'Bamboo mat': 'Large Waste Items',
    'Bedding items': 'Large Waste Items',
    'bicycle': 'Large Waste Items',
    'Carpet': 'Large Waste Items',
    'Clothes drying rack': 'Large Waste Items',
    'Coat rack': 'Large Waste Items',
    'Door panel': 'Large Waste Items',
    'Earthenware jar': 'Large Waste Items',
    'Floor covering': 'Large Waste Items',
    'Frame': 'Large Waste Items',
    'lumber': 'Large Waste Items',
    'Mannequin': 'Large Waste Items',
    'Mat': 'Large Waste Items',
    'Piano': 'Large Waste Items',
    'Rice storage container': 'Large Waste Items',
    'Signboard': 'Large Waste Items',
    'Stroller': 'Large Waste Items',
    'Wall clock': 'Large Waste Items',
    'Water tank': 'Large Waste Items',
    'audio cabinet': 'Large Waste Items',
    'suitcase': 'Large Waste Items',
    
    # ê¸°íƒ€ ì¹´í…Œê³ ë¦¬
    'PP bag': 'PP bag',
    'General waste bag': 'General Waste',
    'waste pile': 'General Waste',
    'CleanNet': 'CleanNet',
    'General Waste': 'General Waste'
}

def calculate_iou(box1, box2):
    """Calculate Intersection over Union between two boxes"""
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    x1_i = max(x1_1, x1_2)
    y1_i = max(y1_1, y1_2)
    x2_i = min(x2_1, x2_2)
    y2_i = min(y2_1, y2_2)
    
    if x2_i < x1_i or y2_i < y1_i:
        return 0.0
    
    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0

def non_max_suppression(boxes, scores, classes, iou_threshold=0.5):
    """Apply Non-Maximum Suppression to remove overlapping detections"""
    if len(boxes) == 0:
        return [], [], []
        
    selected_indices = []
    indices = np.argsort(scores)[::-1]
    
    while len(indices) > 0:
        current_idx = indices[0]
        selected_indices.append(current_idx)
        
        if len(indices) == 1:
            break
            
        ious = [calculate_iou(boxes[current_idx], boxes[idx]) for idx in indices[1:]]
        indices = indices[1:][np.array(ious) < iou_threshold]
    
    return [boxes[i] for i in selected_indices], [scores[i] for i in selected_indices], [classes[i] for i in selected_indices]

def get_bbox_color(class_name, confidence):
    """Get bounding box color based on class and confidence threshold"""
    mapped_class = category_mapping.get(class_name, class_name)
    
    if mapped_class == 'Large Waste Items':
        return (0, 255, 0) if confidence > 0.4 else (0, 0, 255)
    elif mapped_class == 'PP bag':
        return (0, 255, 0) if confidence > 0.5 else (0, 0, 255)
    else:
        return (255, 255, 255)

def parse_location_from_filename(filename):
    parts = filename.split('-')
    if len(parts) >= 5:
        lat = float(f"{parts[1]}.{parts[2]}")
        lon = float(f"{parts[3]}.{parts[4].split('_')[0]}")
        return lat, lon
    return None, None

def parse_time_from_filename(filename):
    time_str = filename[:12]
    try:
        return datetime.strptime(time_str, '%Y%m%d%H%M').strftime('%Y-%m-%d %H:%M:%S')
    except:
        return None

def save_image(uploaded_files):
    for file in uploaded_files:
        if file.name not in st.session_state.images:
            st.session_state["images"].append(file.name)
            with open(f"./data/{file.name}", "wb") as f:
                f.write(file.getbuffer())

def show_map(html_file):
    """HTML íŒŒì¼ì„ ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ë¶ˆëŸ¬ì™€ í‘œì‹œí•©ë‹ˆë‹¤."""
    if os.path.exists(html_file):
        with open(html_file, "r", encoding="utf-8") as f:
            html_content = f.read()
            components.v1.html(html_content, height=600, scrolling=True)
    else:
        st.error("ì§€ë„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def analyze_images():
    base_dir = 'E:/livingLab/livingLab-main/demo'
    model_path = os.path.join(base_dir, 'model/best.pt')  # ëª¨ë¸ ê²½ë¡œ ìˆ˜ì •
    output_dir = os.path.join(base_dir, 'results')
    os.makedirs(output_dir, exist_ok=True)
    
    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(model_path):
        st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None
        
    model = YOLO(model_path)
    results = []
    process_times = []
    
    # st.session_stateì— ìˆëŠ” ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬
    for img_name in st.session_state.images:
        img_path = os.path.join("data", img_name)
        if not os.path.exists(img_path):
            st.error(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            continue
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì¶”ë¡ 
        prediction = model.predict(source=img_path, save=False)[0]
        img = cv2.imread(img_path)
        if img is None:
            st.error(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            continue
        
        process_times.append({
            'preprocess': prediction.speed['preprocess'],
            'inference': prediction.speed['inference'],
            'postprocess': prediction.speed['postprocess']
        })
        
        boxes = []
        scores = []
        class_names = []
        
        for pred in prediction.boxes.data:
            x1, y1, x2, y2, conf, cls = pred
            boxes.append([x1.item(), y1.item(), x2.item(), y2.item()])
            scores.append(conf.item())
            class_names.append(model.names[int(cls.item())])
        
        filtered_boxes, filtered_scores, filtered_classes = non_max_suppression(
            boxes, scores, class_names, iou_threshold=0.5
        )
        
        lat, lon = parse_location_from_filename(img_name)
        time = parse_time_from_filename(img_name)
        
        for cls, conf, box in zip(filtered_classes, filtered_scores, filtered_boxes):
            mapped_class = category_mapping.get(cls, cls)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            x1, y1, x2, y2 = map(int, box)
            color = get_bbox_color(cls, conf)
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            label = f'{cls} {conf:.2f}'
            cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            results.append({
                'Latitude': lat,
                'Longitude': lon,
                'Time': time,
                'Type': mapped_class,
                'Score': round(conf, 3),
                'Image': img_name
            })
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        detected_name = f"{os.path.splitext(img_name)[0]}_detected{os.path.splitext(img_name)[1]}"
        output_path = os.path.join(output_dir, detected_name)
        cv2.imwrite(output_path, img)
        st.write(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    # DataFrame ìƒì„±
    if results:
        df = pd.DataFrame(results)
        
        # results í´ë”ì— CSV íŒŒì¼ ì €ì¥
        # Large Waste Itemsê°€ ì—†ëŠ” ë°ì´í„°
        df_no_large = df[~df['Type'].str.contains('Large Waste Items', na=False)]
        no_large_path = os.path.join(output_dir, 'detection_results_no_large_waste.csv')
        df_no_large.to_csv(no_large_path, index=False, encoding='utf-8-sig')
        st.write(f"Large Waste Items ì œì™¸ CSV ì €ì¥ ì™„ë£Œ: {no_large_path}")
        
        # PP bagì´ ì—†ëŠ” ë°ì´í„°
        df_no_pp = df[~df['Type'].str.contains('PP bag', na=False)]
        no_pp_path = os.path.join(output_dir, 'detection_results_no_pp_bag.csv')
        df_no_pp.to_csv(no_pp_path, index=False, encoding='utf-8-sig')
        st.write(f"PP bag ì œì™¸ CSV ì €ì¥ ì™„ë£Œ: {no_pp_path}")
        
        return df
    else:
        st.warning("ê²€ì¶œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

def make_node_map() :
    visualize_nodemap()

def make_route_map() :
    make_route()
    # time.sleep(100)
    visualize_routemap()

def initalize_state() : 
    if 'images' not in st.session_state:
        st.session_state['images'] = []
    if 'show_map' not in st.session_state :
        st.session_state['show_map'] = False
    if 'page' not in st.session_state:
        st.session_state['page'] = 1  # ì²« ë²ˆì§¸ í˜ì´ì§€ë¡œ ì´ˆê¸°í™”
    if 'selection_status' not in st.session_state:
        # ì„ íƒ ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        data = pd.read_csv('store/route_input.csv')
        st.session_state['selection_status'] = [True] * len(data)
    if 'analysis_results' not in st.session_state:
        st.session_state['analysis_results'] = None


def main():
    st.set_page_config(page_title="ë¦¬ë¹™ë© ë°ëª¨", layout="wide")
    st.title("ğŸ˜ í˜ê¸°ë¬¼ ìˆ˜ê±° ìµœì ê²½ë¡œ íƒìƒ‰")
    initalize_state()
    
    if st.session_state['page'] == 1:
        col1, col2 = st.columns([1, 1])
        with col2:
            # ì»¬ëŸ¼ì„ ë” ì„¸ë¶„í™”í•˜ì—¬ ë¹ˆ ê³µê°„ì„ ë§Œë“¤ê³  ë²„íŠ¼ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™
            cols = st.columns([3, 1, 1])  # 5ê°œì˜ ì»¬ëŸ¼ ìƒì„±

            with cols[1]:  # 4ë²ˆì§¸ ì»¬ëŸ¼ì— ì²« ë²ˆì§¸ ë²„íŠ¼ ë°°ì¹˜
                if st.button("ì´ë¯¸ì§€ ë¶„ì„í•˜ê¸°"):
                    st.session_state['analysis_results'] = analyze_images()
                    make_node_map()
                    time.sleep(1)
                    st.session_state['show_map'] = True
                    st.rerun()

            with cols[2]:  # 5ë²ˆì§¸ ì»¬ëŸ¼ì— ë‘ ë²ˆì§¸ ë²„íŠ¼ ë°°ì¹˜
                if st.button("ê²½ë¡œ ë„ì¶œí•˜ê¸°"):
                    df = pd.read_csv('store/route_input.csv')
                    selected_df = df[st.session_state['selection_status']]
                    selected_df.to_csv('store/route_input_after_demo.csv', index=False)
                    make_route_map()
                    st.session_state['page'] = 2
                    st.rerun()

        col1, col2 = st.columns([1, 1])

        with col1:
            
            if st.session_state['show_map']:
                map_html_file = "store/node_map.html"
                show_map(map_html_file)
            else :
                map_html_file = "store/empty_map.html"
                show_map(map_html_file)
            uploaded_files = st.file_uploader(label="Choose an image file", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
            if uploaded_files:
                save_image(uploaded_files)

            # ì´ë¯¸ì§€ í‘œì‹œ
            if st.session_state["images"]:
                st.write("ì—…ë¡œë“œëœ ì´ë¯¸ì§€:")
                displayed_images = st.session_state["images"]
                cols = st.columns(min(len(displayed_images), 8))  # ìµœëŒ€ 8ì—´ë¡œ í‘œì‹œ
                for index, image_name in enumerate(displayed_images):
                    with cols[index % 8]:
                        st.image(f'data/{image_name}', width=200)
            
        with col2:
                    
            st.markdown("### âœ… íê¸°ë¬¼ ë¦¬ìŠ¤íŠ¸")
            st.markdown('<hr style="margin-top: 0rem; margin-bottom: 0rem;"/>', unsafe_allow_html=True)

            # CSV íŒŒì¼ ì½ê¸°
            if st.session_state['show_map']:

                data = pd.read_csv('store/route_input.csv')
            
                cols = st.columns([1, 30, 1, 25, 1, 15, 1, 15, 1])
                with cols[1]:
                    st.markdown('<p style="margin: 0;"><strong>ì´ë¯¸ì§€</strong></p>', unsafe_allow_html=True)
                with cols[3]:
                    st.markdown('<p style="margin: 0;"><strong>ì£¼ì†Œ</strong></p>', unsafe_allow_html=True)
                with cols[5]:
                    st.markdown('<p style="margin: 0;"><strong>íê¸°ë¬¼ ì¢…ë¥˜</strong></p>', unsafe_allow_html=True)
                with cols[7]:
                    st.markdown('<p style="margin: 0;"><strong>ìˆ˜ê±°ì—¬ë¶€</strong></p>', unsafe_allow_html=True)
                st.markdown('<hr style="margin-top: 0rem;"/>', unsafe_allow_html=True)

                for i, row in data.iterrows():
                    if i == 0 or i == len(data)-1 :
                        continue
                    cols = st.columns([1, 30, 1, 25, 1, 15, 1, 15, 1])
                    with cols[1]:
                        st.image(f'data/{row['image']}', width=1000)  # ì´ë¯¸ì§€ URL í˜¹ì€ ê²½ë¡œ
                    with cols[3]:
                        st.write(f'{row['address']}')
                    with cols[5]:
                        # íê¸°ë¬¼ ì¢…ë¥˜ë¥¼ ì„¸ë¡œ ì¤‘ì•™ì— ì •ë ¬
                        st.markdown(f'<div style="display: flex; align-items: center; height: 100%;">{row['type']}</div>', unsafe_allow_html=True)
                
                    with cols[7]:
                        # ì²´í¬ë°•ìŠ¤ë¡œ íê¸°ë¬¼ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
                        checkbox_label = f"Select {row['type']} at {row['address']}"
                        is_selected = st.checkbox(checkbox_label, key=i, value=st.session_state['selection_status'][i], label_visibility="collapsed")
                        # ì„ íƒ ìƒíƒœ ì—…ë°ì´íŠ¸
                        st.session_state['selection_status'][i] = is_selected

                    # ê° ë°ì´í„° ì•„ë˜ì— ì„  ê·¸ë¦¬ê¸°
                    st.markdown('<hr style="margin-top: 0.5rem;"/>', unsafe_allow_html=True)

    elif st.session_state['page'] == 2:
        if st.button("ì´ì „ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state['page'] = 1
            st.rerun()

        col1, col2 = st.columns([2, 1])
        data = pd.read_csv('store/result.csv')
        df = data[:-2]
        with col1:
            map_html_file = 'store/result_waste_route_map.html'
            show_map(map_html_file)

        with col2:
            st.markdown("## íê¸°ë¬¼ ìˆ˜ê±° ê²½ë¡œ")

            # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
            table_data = df[['ìˆ˜ê±°ìˆœì„œ','ì“°ë ˆê¸°í™•ì¸ì‹œê°„', 'ìœ„ë„', 'ê²½ë„', 'íê¸°ë¬¼ì¢…ë¥˜', 'íê¸°ë¬¼ê°œìˆ˜']].copy()
            
            table_data['ìœ„ì¹˜'] = table_data.apply(lambda row: f"{row['ìœ„ë„']:.4f}, {row['ê²½ë„']:.4f}", axis=1)# <------------------------------------------------- ì—¬ê¸°ì„œ ìœ„ë„ ê²½ë„ ìˆ˜ì • í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

            table_data = table_data.drop(['ìœ„ë„', 'ê²½ë„'], axis=1) 

            table_data['ì“°ë ˆê¸°í™•ì¸ì‹œê°„'] = pd.to_datetime(table_data['ì“°ë ˆê¸°í™•ì¸ì‹œê°„']).dt.strftime('%Y-%m-%d %H:%M:%S')
            table_data = table_data[['ìˆ˜ê±°ìˆœì„œ','ì“°ë ˆê¸°í™•ì¸ì‹œê°„', 'ìœ„ì¹˜', 'íê¸°ë¬¼ì¢…ë¥˜', 'íê¸°ë¬¼ê°œìˆ˜']]

            # íê¸°ë¬¼ ê°œìˆ˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            table_data['íê¸°ë¬¼ê°œìˆ˜'] = table_data['íê¸°ë¬¼ê°œìˆ˜'].astype(int)

            # í…Œì´ë¸” í‘œì‹œ (ì¸ë±ìŠ¤ ìˆ¨ê¹€)
            st.dataframe(table_data, hide_index=True, column_config={
                "íê¸°ë¬¼ê°œìˆ˜": st.column_config.NumberColumn(
                    "íê¸°ë¬¼ê°œìˆ˜",
                    help="ìˆ˜ê±°í•  íê¸°ë¬¼ì˜ ê°œìˆ˜",
                    format="%d"
                )
            })


if __name__ == "__main__":
    main()
