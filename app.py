##  ! í„°ë¯¸ë„ì— "streamlit run app.py" ë¼ê³  ì…ë ¥í•˜ë©´ ì‹¤í–‰ë¨ 

import glob
import time
import numpy as np
import streamlit as st
import os
import pandas as pd
from datetime import datetime
from streamlit import components
from ultralytics import YOLO
import cv2

from src.address_changer.addrChanger import image_to_route_changer
from src.main import make_route
from src.visualize.visualize_nodes import visualize_nodemap
from src.visualize.visualize_routes import visualize_routemap

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì •ì˜
category_mapping = {
    # Large Waste Items
    'arcade machine': 'Large Waste Items',
    'Audio': 'Large Waste Items',
    'Computer': 'Large Waste Items',
    'fax machine': 'Large Waste Items',
    'Main unit': 'Large Waste Items',
    'Monitor': 'Large Waste Items',
    'Printer': 'Large Waste Items',
    'sewing machine': 'Large Waste Items',
    'Speaker': 'Large Waste Items',
    'typewriter': 'Large Waste Items',
    'Vacuum cleaner': 'Large Waste Items',
    'Video player': 'Large Waste Items',
    'Bathtub': 'Large Waste Items',
    'Sink': 'Large Waste Items',
    'Kitchen sink': 'Large Waste Items',
    'Toilet bowl': 'Large Waste Items',
    'Bed': 'Large Waste Items',
    'Bookcase': 'Large Waste Items',
    'Bookstand': 'Large Waste Items',
    'Cabinet': 'Large Waste Items',
    'chair': 'Large Waste Items',
    'Cupboard': 'Large Waste Items',
    'Desk': 'Large Waste Items',
    'Dining table': 'Large Waste Items',
    'Display cabinet': 'Large Waste Items',
    'Display stand': 'Large Waste Items',
    'Drawer unit': 'Large Waste Items',
    'Shoe rack': 'Large Waste Items',
    'Small cabinet': 'Large Waste Items',
    'Sofa': 'Large Waste Items',
    'Table': 'Large Waste Items',
    'TV stand': 'Large Waste Items',
    'Vanity table': 'Large Waste Items',
    'Wardrobe': 'Large Waste Items',
    'Air conditioner': 'Large Waste Items',
    'Air purifier': 'Large Waste Items',
    'dish dryer': 'Large Waste Items',
    'Electric rice cooker': 'Large Waste Items',
    'Fan': 'Large Waste Items',
    'Gas oven range': 'Large Waste Items',
    'Heater': 'Large Waste Items',
    'Humidifier': 'Large Waste Items',
    'Microwave': 'Large Waste Items',
    'refrigerator': 'Large Waste Items',
    'Spin dryer': 'Large Waste Items',
    'TV': 'Large Waste Items',
    'Washing machine': 'Large Waste Items',
    'Aquarium': 'Large Waste Items',
    'Bamboo mat': 'Large Waste Items',
    'Bedding items': 'Large Waste Items',
    'bicycle': 'Large Waste Items',
    'Carpet': 'Large Waste Items',
    'Clothes drying rack': 'Large Waste Items',
    'Coat rack': 'Large Waste Items',
    'Door panel': 'Large Waste Items',
    'Earthenware jar': 'Large Waste Items',
    'Floor covering': 'Large Waste Items',
    'Frame': 'Large Waste Items',
    'lumber': 'Large Waste Items',
    'Mannequin': 'Large Waste Items',
    'Mat': 'Large Waste Items',
    'Piano': 'Large Waste Items',
    'Rice storage container': 'Large Waste Items',
    'Signboard': 'Large Waste Items',
    'Stroller': 'Large Waste Items',
    'Wall clock': 'Large Waste Items',
    'Water tank': 'Large Waste Items',
    'audio cabinet': 'Large Waste Items',
    'suitcase': 'Large Waste Items',
    
    # ê¸°íƒ€ ì¹´í…Œê³ ë¦¬
    'PP bag': 'PP bag',
    'General waste bag': 'General Waste',
    'waste pile': 'General Waste',
    'CleanNet': 'CleanNet',
    'General Waste': 'General Waste'
}

def calculate_iou(box1, box2):
    """Calculate Intersection over Union between two boxes"""
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    x1_i = max(x1_1, x1_2)
    y1_i = max(y1_1, y1_2)
    x2_i = min(x2_1, x2_2)
    y2_i = min(y2_1, y2_2)
    
    if x2_i < x1_i or y2_i < y1_i:
        return 0.0
    
    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0

def non_max_suppression(boxes, scores, classes, iou_threshold=0.5):
    """Apply Non-Maximum Suppression to remove overlapping detections"""
    if len(boxes) == 0:
        return [], [], []
        
    selected_indices = []
    indices = np.argsort(scores)[::-1]
    
    while len(indices) > 0:
        current_idx = indices[0]
        selected_indices.append(current_idx)
        
        if len(indices) == 1:
            break
            
        ious = [calculate_iou(boxes[current_idx], boxes[idx]) for idx in indices[1:]]
        indices = indices[1:][np.array(ious) < iou_threshold]
    
    return [boxes[i] for i in selected_indices], [scores[i] for i in selected_indices], [classes[i] for i in selected_indices]

def get_bbox_color(class_name, confidence):
    """Get bounding box color based on class and confidence threshold"""
    mapped_class = category_mapping.get(class_name, class_name)
    
    if mapped_class == 'Large Waste Items':
        return (0, 255, 0) if confidence > 0.4 else (0, 0, 255)
    elif mapped_class == 'PP bag':
        return (0, 255, 0) if confidence > 0.5 else (0, 0, 255)
    else:
        return (255, 255, 255)

def parse_location_from_filename(filename):
    parts = filename.split('-')
    if len(parts) >= 5:
        lat = float(f"{parts[1]}.{parts[2]}")
        lon = float(f"{parts[3]}.{parts[4].split('_')[0]}")
        return lat, lon
    return None, None

def parse_time_from_filename(filename):
    time_str = filename[:12]
    try:
        return datetime.strptime(time_str, '%Y%m%d%H%M').strftime('%Y-%m-%d %H:%M:%S')
    except:
        return None

def save_image(uploaded_files):
    for file in uploaded_files:
        if file.name not in st.session_state.images:
            st.session_state["images"].append(file.name)
            with open(f"./data/{file.name}", "wb") as f:
                f.write(file.getbuffer())

def show_map(html_file):
    """HTML íŒŒì¼ì„ ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ë¶ˆëŸ¬ì™€ í‘œì‹œí•©ë‹ˆë‹¤."""
    if os.path.exists(html_file):
        with open(html_file, "r", encoding="utf-8") as f:
            html_content = f.read()
            components.v1.html(html_content, height=600, scrolling=True)
    else:
        st.error("ì§€ë„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def analyze_images():
    # base_dir = 'E:/livingLab/livingLab-main/demo'
    # model_path = os.path.join(base_dir, 'model/best.pt')  # ëª¨ë¸ ê²½ë¡œ ìˆ˜ì •
    model_path = 'model/best.pt'
    # output_dir = os.path.join(base_dir, 'results')
    output_dir = 'results'
    os.makedirs(output_dir, exist_ok=True)
    
    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(model_path):
        st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None
        
    model = YOLO(model_path)
    results = []
    process_times = []
    
    # st.session_stateì— ìˆëŠ” ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬
    for img_name in st.session_state.images:
        img_path = os.path.join("data", img_name)
        if not os.path.exists(img_path):
            st.error(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            continue
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì¶”ë¡ 
        prediction = model.predict(source=img_path, save=False)[0]
        img = cv2.imread(img_path)
        if img is None:
            st.error(f"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            continue
        
        process_times.append({
            'preprocess': prediction.speed['preprocess'],
            'inference': prediction.speed['inference'],
            'postprocess': prediction.speed['postprocess']
        })
        
        boxes = []
        scores = []
        class_names = []
        
        for pred in prediction.boxes.data:
            x1, y1, x2, y2, conf, cls = pred
            boxes.append([x1.item(), y1.item(), x2.item(), y2.item()])
            scores.append(conf.item())
            class_names.append(model.names[int(cls.item())])
        
        filtered_boxes, filtered_scores, filtered_classes = non_max_suppression(
            boxes, scores, class_names, iou_threshold=0.5
        )
        
        lat, lon = parse_location_from_filename(img_name)
        time = parse_time_from_filename(img_name)
        
        for cls, conf, box in zip(filtered_classes, filtered_scores, filtered_boxes):
            mapped_class = category_mapping.get(cls, cls)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            x1, y1, x2, y2 = map(int, box)
            color = get_bbox_color(cls, conf)
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
            label = f'{cls} {conf:.2f}'
            cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            results.append({
                'Latitude': lat,
                'Longitude': lon,
                'Time': time,
                'Type': mapped_class,
                'Score': round(conf, 3),
                'Image': img_name
            })
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        # detected_name = f"{os.path.splitext(img_name)[0]}_detected{os.path.splitext(img_name)[1]}"
        detected_name = f"{os.path.splitext(img_name)[0]}{os.path.splitext(img_name)[1]}"
        output_path = os.path.join(output_dir, detected_name)
        cv2.imwrite(output_path, img)
        print(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    # DataFrame ìƒì„±
    if results:
        df = pd.DataFrame(results)
        
        # results í´ë”ì— CSV íŒŒì¼ ì €ì¥
        # Large Waste Itemsê°€ ì—†ëŠ” ë°ì´í„°
        df_no_large = df[~df['Type'].str.contains('Large Waste Items', na=False)]
        no_large_path = os.path.join(output_dir, 'detection_results_no_large_waste.csv')
        df_no_large.to_csv(no_large_path, index=False, encoding='utf-8-sig')
        print(f"Large Waste Items ì œì™¸ CSV ì €ì¥ ì™„ë£Œ: {no_large_path}")
        
        # PP bagì´ ì—†ëŠ” ë°ì´í„°
        df_no_pp = df[~df['Type'].str.contains('PP bag', na=False)]
        no_pp_path = os.path.join(output_dir, 'detection_results_no_pp_bag.csv')
        df_no_pp.to_csv(no_pp_path, index=False, encoding='utf-8-sig')
        print(f"PP bag ì œì™¸ CSV ì €ì¥ ì™„ë£Œ: {no_pp_path}")
        
        return df
    else:
        st.warning("ê²€ì¶œëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None


def initalize_state() : 
    if 'page' not in st.session_state:
        st.session_state['page'] = 1
    if 'images' not in st.session_state:
        st.session_state['images'] = []
    if 'route_input_path' not in st.session_state:
        st.session_state['route_input_path'] = 'store/route_input.csv'
    if 'type_choice' not in st.session_state:
        st.session_state['type_choice'] = None
    if 'show_nodemap' not in st.session_state :
        st.session_state['show_nodemap'] = False
    if 'nodemap_path' not in st.session_state :
        st.session_state['nodemap_path'] = 'store/empty_map.html'

def make_route_map() :
    make_route()
    type = "Large Waste Items" if st.session_state['type_choice']=='ëŒ€í˜•íê¸°ë¬¼' else "PP bag"
    visualize_routemap(type)

def initalize_checkbox_state() :
    if 'pp_selection_status' not in st.session_state:
        data = pd.read_csv('store/route_input_pp.csv')
        st.session_state['pp_selection_status'] = [True] * len(data)
    if 'large_selection_status' not in st.session_state:
        data = pd.read_csv('store/route_input_large.csv')
        st.session_state['large_selection_status'] = [True] * len(data)

# íê¸°ë¬¼ ì¢…ë¥˜ stateì— ë”°ë¼ ìµœì ê²½ë¡œ input pathë¥¼ ë³€ê²½í•˜ëŠ” ìœ í‹¸í•¨ìˆ˜.
def change_type_state(type_choice) :
    st.session_state['type_choice'] = type_choice
    
    if type_choice == 'ëŒ€í˜•íê¸°ë¬¼':
        st.session_state['route_input_path'] = 'store/route_input_large.csv'
        st.session_state['nodemap_path'] = 'store/node_map_large.html'
    elif type_choice == 'ppë§ˆëŒ€':
        st.session_state['route_input_path'] = 'store/route_input_pp.csv'
        st.session_state['nodemap_path'] = 'store/node_map_pp.html'
    else:
        st.session_state['route_input_path'] = 'store/route_input.csv'
        st.session_state['nodemap_path'] = 'store/empty_map.html'
    st.rerun()


def main():
    st.set_page_config(page_title="ë¦¬ë¹™ë© ë°ëª¨", layout="wide")
    st.title("ğŸ˜ í˜ê¸°ë¬¼ ìˆ˜ê±° ìµœì ê²½ë¡œ íƒìƒ‰")
    initalize_state()

    ##############
    ### PAGE 1 ###
    ##############
    if st.session_state['page'] == 1:

        ## ì˜¤ë¥¸ìª½ ë²„íŠ¼ Layout ##
        col1, col2 = st.columns([1, 1])

        with col2:
            cols = st.columns([3, 1, 1, 1])

            with cols[1]:
                if st.button("ì´ë¯¸ì§€ ë¶„ì„í•˜ê¸°"):
                    analyze_images()
                    image_to_route_changer()
                    visualize_nodemap()
                    time.sleep(1)
                    initalize_checkbox_state()
                    st.session_state['show_nodemap'] = True
                    st.rerun()

            with cols[2]:
                if st.button("ê²½ë¡œ ë„ì¶œí•˜ê¸°"):
                    route_input_path = st.session_state['route_input_path']
                    type_choice = st.session_state['type_choice']
                    route_input_df = pd.read_csv(route_input_path)
                    if type_choice == 'ëŒ€í˜•íê¸°ë¬¼':
                        selected_df = route_input_df[st.session_state['large_selection_status']]
                    elif type_choice == 'ppë§ˆëŒ€':
                        selected_df = route_input_df[st.session_state['pp_selection_status']]
                        
                    selected_df.to_csv('store/route_input_after_demo.csv', index=False)
                    make_route_map()
                    st.session_state['page'] = 2
                    st.rerun()

            with cols[3]: 
                type = ['ëŒ€í˜•íê¸°ë¬¼', 'ppë§ˆëŒ€']
                current_choice = st.selectbox('íê¸°ë¬¼ ì¢…ë¥˜', type, label_visibility="collapsed")
                previous_choice = st.session_state['type_choice']

                if current_choice != previous_choice:
                    change_type_state(current_choice)


        ## ì§€ë„ / ë¦¬ìŠ¤íŠ¸ Layout ##
        col1, col2 = st.columns([1, 1])

        with col1:
            
            ## ì§€ë„ Section
            map_html_file = 'store/empty_map.html'
            if st.session_state['show_nodemap']:
                map_html_file = st.session_state['nodemap_path']
            show_map(map_html_file)

            ## ì´ë¯¸ì§€ ì—…ë¡œë“œ Section
            uploaded_files = st.file_uploader(label="Choose an image file", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
            if uploaded_files:
                save_image(uploaded_files)

            ## ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° Section
            if st.session_state["images"]:
                st.write("ì—…ë¡œë“œëœ ì´ë¯¸ì§€:")
                displayed_images = st.session_state["images"]
                cols = st.columns(min(len(displayed_images), 8))  # ìµœëŒ€ 8ì—´ë¡œ í‘œì‹œ
                for index, image_name in enumerate(displayed_images):
                    with cols[index % 8]:
                        st.image(f'data/{image_name}', width=200)
            
        with col2:
            st.markdown("### âœ… íê¸°ë¬¼ ë¦¬ìŠ¤íŠ¸")
            st.markdown('<hr style="margin-top: 0rem; margin-bottom: 0rem;"/>', unsafe_allow_html=True)

            if st.session_state['show_nodemap']:
                trash_data = pd.read_csv(st.session_state['route_input_path'])

                ## íê¸°ë¬¼ ë¦¬ìŠ¤íŠ¸ í—¤ë” Section
                cols = st.columns([1, 30, 1, 25, 1, 15, 1, 15, 1])
                with cols[1]:
                    st.markdown('<p style="margin: 0;"><strong>ì´ë¯¸ì§€</strong></p>', unsafe_allow_html=True)
                with cols[3]:
                    st.markdown('<p style="margin: 0;"><strong>ì£¼ì†Œ</strong></p>', unsafe_allow_html=True)
                with cols[5]:
                    st.markdown('<p style="margin: 0;"><strong>íê¸°ë¬¼ ì¢…ë¥˜</strong></p>', unsafe_allow_html=True)
                with cols[7]:
                    st.markdown('<p style="margin: 0;"><strong>ìˆ˜ê±°ì—¬ë¶€</strong></p>', unsafe_allow_html=True)
                st.markdown('<hr style="margin-top: 0rem;"/>', unsafe_allow_html=True)

                ## íê¸°ë¬¼ ë¦¬ìŠ¤íŠ¸ ë°”ë”” Section
                for i, row in trash_data.iterrows():
                    # 1ë²ˆ, ëë²ˆ ë°ì´í„°ëŠ” (ìœ )ì˜¤ì„±ì•Œì”¨.
                    if i == 0 :
                        continue
                    
                    # ë¦¬ìŠ¤íŠ¸ (ì´ë¯¸ì§€, ì£¼ì†Œ, íê¸°ë¬¼ ì¢…ë¥˜, ìˆ˜ê±°ì—¬ë¶€)
                    cols = st.columns([1, 30, 1, 25, 1, 15, 1, 15, 1])
                    with cols[1]:
                        st.image(f'results/{row["image"]}', width=1000)
                    with cols[3]:
                        st.write(f'{row["address"]}')
                    with cols[5]:
                        st.markdown(f'<div style="display: flex; align-items: center; height: 100%;">{row["type"]}</div>', unsafe_allow_html=True)
                    with cols[7]:
                        checkbox_label = f"Select {row['type']} at {row['address']}"
                        if st.session_state['type_choice'] == 'ëŒ€í˜•íê¸°ë¬¼' :
                            checkbox_value =  st.session_state['large_selection_status']
                        elif st.session_state['type_choice'] == 'ppë§ˆëŒ€' :
                            checkbox_value =  st.session_state['pp_selection_status']
                        is_selected = st.checkbox(checkbox_label, key=i, value=checkbox_value[i], label_visibility="collapsed")
                        if is_selected != checkbox_value[i] :
                            checkbox_value[i] = is_selected

                    # ê° ë°ì´í„° ì•„ë˜ ì„ 
                    st.markdown('<hr style="margin-top: 0.5rem;"/>', unsafe_allow_html=True)

            else : 
                st.write("ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ë¶„ì„í•´ì£¼ì„¸ìš”.")


    ##############
    ### PAGE 2 ###
    ##############
    elif st.session_state['page'] == 2:
        if st.button("ì´ì „ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state['page'] = 1
            st.rerun()

        col1, col2 = st.columns([2, 1])

        data = pd.read_csv('store/result.csv')
        df = data[:-2]

        with col1:
            map_html_file = 'store/result_map.html'
            show_map(map_html_file)

        with col2:
            st.markdown("## íê¸°ë¬¼ ìˆ˜ê±° ê²½ë¡œ")

            # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
            table_data = df[['ìˆ˜ê±°ìˆœì„œ', 'ì´ë¯¸ì§€', 'ìœ„ì¹˜', 'íê¸°ë¬¼ì¢…ë¥˜', 'ì“°ë ˆê¸°í™•ì¸ì‹œê°„']].copy()

            table_data['ì“°ë ˆê¸°í™•ì¸ì‹œê°„'] = pd.to_datetime(table_data['ì“°ë ˆê¸°í™•ì¸ì‹œê°„']).dt.strftime('%Y-%m-%d %H:%M:%S')
            table_data = table_data[['ìˆ˜ê±°ìˆœì„œ', 'ì´ë¯¸ì§€', 'ìœ„ì¹˜', 'íê¸°ë¬¼ì¢…ë¥˜', 'ì“°ë ˆê¸°í™•ì¸ì‹œê°„']]

            # í…Œì´ë¸” í‘œì‹œ (ì¸ë±ìŠ¤ ìˆ¨ê¹€)
            st.dataframe(table_data, hide_index=True)


if __name__ == "__main__":
    main()
